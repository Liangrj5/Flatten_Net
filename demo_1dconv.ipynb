{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Function\n",
    "def get_parameter_number(net):\n",
    "    total_num = sum(p.numel() for p in net.parameters())\n",
    "    trainable_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    return {'Total': total_num, 'Trainable': trainable_num}\n",
    "\n",
    "dtype = torch.float\n",
    "\n",
    "class RandomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, size, length):\n",
    "        self.len = length\n",
    "        self.data = torch.randn(length, *size ,dtype = dtype)\n",
    "        self.label = torch.rand(1, dtype = dtype)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "        \n",
    "def Random_DataLoader():\n",
    "    input_size = [3]\n",
    "\n",
    "    train_img_loader = DataLoader(dataset=RandomDataset(input_size, length = 100),\n",
    "                         batch_size=2, shuffle=True)\n",
    "    val_img_loader =  DataLoader(dataset=RandomDataset(input_size, length = 10),\n",
    "                         batch_size=2, shuffle=False)\n",
    "\n",
    "    return train_img_loader, val_img_loader\n",
    "\n",
    "\n",
    "trainloader, valloader =  Random_DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, bias=None):\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "        output = input.mm(weight.t())\n",
    "        print(input.size())\n",
    "        print(weight.size())\n",
    "        print(output.size())\n",
    "        \n",
    "        if bias is not None:\n",
    "            output += bias.unsqueeze(0).expand_as(output)\n",
    "            \n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "#         print(grad_output)\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        \n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "\n",
    "        \n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = grad_output.mm(weight)\n",
    "\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = grad_output.t().mm(input)\n",
    "\n",
    "                 \n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            \n",
    "            grad_bias = grad_output.sum(0).squeeze(0)\n",
    "            grad_bias = grad_bias.view_as(bias)\n",
    "#         print(\"*\" * 40)\n",
    "#         print(bias.size())\n",
    "#         print(grad_weight.size())\n",
    "#         print(grad_bias.size())\n",
    "#         print(\"*\" * 40)\n",
    "        return grad_input, grad_weight, grad_bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, input_features, output_features, bias=True):\n",
    "        super(Linear, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.output_features = output_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(output_features, input_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(output_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.weight.data.uniform_(-0.1, 0.1)\n",
    "        if bias is not None:\n",
    "            self.bias.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # See the autograd section for explanation of what happens here.\n",
    "        return LinearFunction.apply(input, self.weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        # (Optional)Set the extra information about this module. You can test\n",
    "        # it by printing an object of this class.\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([2, 1])\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "demo_net = Linear(3,1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(demo_net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        \n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = demo_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        break\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test 2d transform matrix\n",
    "input_matrix = torch.rand(2, 6)\n",
    "\n",
    "kernel_size = 3\n",
    "input_channels = 2\n",
    "output_channels = 2\n",
    "ks = kernel_size // 2\n",
    "per_col = len(ls) - ks -1\n",
    "transform_maxtrix = torch.zeros([per_col * 2 , kernel_size])\n",
    "fil  = torch.rand([3,output_channels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index in range(len(input_matrix)):\n",
    "    ls = input_matrix[index,:]\n",
    "    for i in range(ks, len(ls) - ks):\n",
    "        transform_maxtrix[i-1 + index * per_col,:] = ls[i-ks: i+ks+1]\n",
    "\n",
    "\n",
    "output_matrix = transform_maxtrix.mm(fil)\n",
    "output = output.T\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[111, 121, 112, 122],\n",
       "       [211, 221, 212, 222]])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### test reshape order\n",
    "a = np.array([[[111,112],[121,122]],[[211,212],[221,222]]])\n",
    "a.reshape(2,-1, order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test conv1d kernel and input shape\n",
    "# input size = [conv_num, kernel_size * in_channels]\n",
    "# kernel matirx shape = [kernel_size * in_channels, out_channels]\n",
    "\n",
    "# test no batch_size\n",
    "a = torch.rand([3,4,5])\n",
    "# a shape = [in_channels, row, col]\n",
    "a = a.reshape([3, -1])\n",
    "# a shape = [in_channels, row * col]\n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test 4d transform matrix\n",
    "\n",
    "a = torch.rand([2,3,4,5])\n",
    "b = a.reshape(-1,a.size(3))\n",
    "len_row = a.size(3)\n",
    "# b.size() = [batch_size * x * y, z]\n",
    "# print(a)\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([72, 3])"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### test 4d transform matrix\n",
    "half_kernel_size = kernel_size // 2\n",
    "kernel_size = 3\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "res = torch.empty([0])\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "        res = torch.cat([res,temp],dim = 0)  \n",
    "    # there is copy, don't warry about editing other torch\n",
    "\n",
    "res = res.reshape(-1,kernel_size)\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([72, 1])\n",
      "torch.Size([2, 3, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "### test 4d transform matrix\n",
    "kernel = torch.rand([3,1])\n",
    "out = res.mm(kernel)\n",
    "print(out.size())\n",
    "c = out.reshape(2,3,4,-1)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test in_channels conv1\n",
    "a = torch.rand([2,3,4,5])\n",
    "# a.size() = batch_size, in_channels, row, col\n",
    "# a.size() = batch_size, row, col, in_channels\n",
    "a =a.permute(0, 2, 3, 1)\n",
    "a.size()\n",
    "len_row = a.size(3)\n",
    "b = a.reshape(-1,len_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 3])"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test in_channels conv1\n",
    "\n",
    "kernel_size = 3\n",
    "half_kernel_size = kernel_size // 2\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "res = torch.empty([0])\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "        res = torch.cat([res,temp],dim = 0)  \n",
    "    # there is copy, don't warry about editing other torch\n",
    "\n",
    "res = res.reshape(-1,kernel_size)\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test in_channels conv1\n",
    "\n",
    "kernel = torch.rand([3,1])\n",
    "out = res.mm(kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "#test in_channels conv1\n",
    "\n",
    "c = out.reshape(2,4,5,-1)\n",
    "c =c.permute(0, 3, 1, 2)\n",
    "\n",
    "# c.size() = batch, col, row, out_channels\n",
    "print(c.size())\n",
    "# print(out)\n",
    "# print(c)\n",
    "# out.size = [batch_size, out_channels, row, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "#test row conv1\n",
    "\n",
    "c =c.permute(0, 1, 3, 2)\n",
    "# a.size() = batch_size, col, , out_channels\n",
    "\n",
    "print(c.size())\n",
    "len_row = c.size(3)\n",
    "b = c.reshape(-1,len_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 3])"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test row conv1\n",
    "\n",
    "\n",
    "kernel_size = 3\n",
    "half_kernel_size = kernel_size // 2\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "res = torch.empty([0])\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "        res = torch.cat([res,temp],dim = 0)  \n",
    "    # there is copy, don't warry about editing other torch\n",
    "\n",
    "res = res.reshape(-1,kernel_size)\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test row conv1\n",
    "\n",
    "kernel = torch.rand([3,1])\n",
    "out = res.mm(kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2, 5])"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test in_channels conv1\n",
    "\n",
    "d = out.reshape(2, 1, 5,-1)\n",
    "d =d.permute(0, 1, 3, 2)\n",
    "\n",
    "# c.size() = batch, col, row, out_channels\n",
    "# print(c.size())\n",
    "# print(out)\n",
    "# print(c)\n",
    "# out.size = [batch_size, out_channels, row, col]\n",
    "d.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 3])"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test col conv1\n",
    "\n",
    "e =d\n",
    "# a.size() = batch_size, col, , out_channels\n",
    "\n",
    "print(e.size())\n",
    "len_row = e.size(3)\n",
    "b = e.reshape(-1,len_row)\n",
    "\n",
    "kernel_size = 3\n",
    "half_kernel_size = kernel_size // 2\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "res = torch.empty([0])\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "        res = torch.cat([res,temp],dim = 0)  \n",
    "    # there is copy, don't warry about editing other torch\n",
    "\n",
    "res = res.reshape(-1,kernel_size)\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2, 3])"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test col conv1\n",
    "\n",
    "kernel = torch.rand([3,1])\n",
    "out = res.mm(kernel)\n",
    "\n",
    "f = out.reshape(2, 1, 2,-1)\n",
    "\n",
    "# c.size() = batch, col, row, out_channels\n",
    "# print(c.size())\n",
    "# print(out)\n",
    "# print(c)\n",
    "# out.size = [batch_size, out_channels, row, col]\n",
    "f.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: torch.Size([2, 4, 5, 3])\n",
      "res: torch.Size([40, 3])\n",
      "out_L: torch.Size([2, 2, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "#test mul_out_channels, in_channels part\n",
    "a = torch.rand([2,3,4,5])\n",
    "a =a.permute(0, 2, 3, 1)\n",
    "# a.size() = batch_size, row, col, in_channels\n",
    "\n",
    "print('a:',a.size())\n",
    "len_row = a.size(3)\n",
    "b = a.reshape(-1,len_row)\n",
    "\n",
    "\n",
    "kernel_size = 3\n",
    "half_kernel_size = kernel_size // 2\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "res = torch.empty([0])\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "        res = torch.cat([res,temp],dim = 0)  \n",
    "    # there is copy, don't warry about editing other torch\n",
    "\n",
    "res = res.reshape(-1,kernel_size)\n",
    "print('res:', res.size())\n",
    "\n",
    "\n",
    "\n",
    "L_kernel = torch.rand([3,2])\n",
    "out = res.mm(L_kernel)\n",
    "\n",
    "\n",
    "out_L = out.reshape(2,4,5,-1)\n",
    "out_L =out_L.permute(0, 3, 1, 2)\n",
    "\n",
    "# c.size() = batch, out_channels, row, col\n",
    "print('out_L:',out_L.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_H: torch.Size([2, 2, 5, 4])\n",
      "res: torch.Size([40, 3])\n",
      "out: torch.Size([40, 1])\n",
      "out_H: torch.Size([2, 2, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "#test mul_out_channels, row part\n",
    "\n",
    "in_H =out_L.permute(0, 1, 3, 2)\n",
    "# c.size() = batch, out_channels, col ,row\n",
    "\n",
    "\n",
    "print('in_H:',in_H.size())\n",
    "len_row = in_H.size(3)\n",
    "b = in_H.reshape(-1,len_row)\n",
    "\n",
    "#test row conv1\n",
    "\n",
    "\n",
    "kernel_size = 3\n",
    "half_kernel_size = kernel_size // 2\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "res = torch.empty([0])\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "        res = torch.cat([res,temp],dim = 0)  \n",
    "    # there is copy, don't warry about editing other torch\n",
    "\n",
    "res = res.reshape(-1,kernel_size)\n",
    "print('res:', res.size())\n",
    "\n",
    "\n",
    "kernel = torch.rand([3, 1]) #out_channels,1])\n",
    "out = res.mm(kernel)\n",
    "print('out:', out.size())\n",
    "\n",
    "# #test in_channels conv1\n",
    "# \n",
    "out_H = out.reshape(2, 2, 5,-1)\n",
    "out_H =out_H.permute(0, 1, 3, 2)\n",
    "print('out_H:', out_H.size())\n",
    "\n",
    "# # c.size() = batch, col, row, out_channels\n",
    "# # print(c.size())\n",
    "# # print(out)\n",
    "# # print(c)\n",
    "# # out.size = [batch_size, out_channels, row, col]\n",
    "# d.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_L: torch.Size([2, 2, 4, 5])\n",
      "res: torch.Size([20, 6])\n",
      "out: torch.Size([20, 1])\n",
      "out_H: torch.Size([2, 2, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "#test mul_out_channels, row part\n",
    "out_channels = 2\n",
    "len_row = out_L.size(2)\n",
    "kernel_size = 3\n",
    "half_kernel_size = kernel_size // 2\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "print('out_L:', out_L.size())\n",
    "in_H =out_L.permute(1, 0, 2, 3)\n",
    "# c.size() = out_channels, batch, row, col\n",
    "\n",
    "res = []\n",
    "for index1,per_channel in enumerate(in_H):\n",
    "\n",
    "    \n",
    "    \n",
    "    per_channel.permute(0,2,1)\n",
    "    per_channel = per_channel.reshape(-1,len_row)\n",
    "    \n",
    "    temp_res = []\n",
    "    \n",
    "    for i in per_channel:\n",
    "        for index in range(index_start, index_end):\n",
    "            temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "            temp_res.append(temp)\n",
    "            \n",
    "    temp_res = torch.cat(temp_res,dim = 0)\n",
    "    temp_res = temp_res.reshape(-1,kernel_size)\n",
    "    res.append(temp_res)\n",
    "\n",
    "res = torch.cat(res,dim = 1)\n",
    "print('res:', res.size())\n",
    "\n",
    "kernel = torch.rand([3 * 2, 1]) #out_channels,1])\n",
    "out = res.mm(kernel)\n",
    "print('out:', out.size())\n",
    "\n",
    "out_H = out.reshape(2, 2, 5,-1)\n",
    "out_H =out_H.permute(0, 1, 3, 2)\n",
    "print('out_H:', out_H.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test mul_out_channels, row part\n",
    "out_channels = 2\n",
    "len_row = out_L.size(2)\n",
    "kernel_size = 3\n",
    "half_kernel_size = kernel_size // 2\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "print('out_L:', out_L.size())\n",
    "in_H =out_L.permute(1, 0, 2, 3)\n",
    "# c.size() = out_channels, batch, row, col\n",
    "\n",
    "res = []\n",
    "for index1,per_channel in enumerate(in_H):\n",
    "\n",
    "    \n",
    "    \n",
    "    per_channel.permute(0,2,1)\n",
    "    per_channel = per_channel.reshape(-1,len_row)\n",
    "    \n",
    "    temp_res = []\n",
    "    \n",
    "    for i in per_channel:\n",
    "        for index in range(index_start, index_end):\n",
    "            temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "            temp_res.append(temp)\n",
    "            \n",
    "    temp_res = torch.cat(temp_res,dim = 0)\n",
    "    temp_res = temp_res.reshape(-1,kernel_size)\n",
    "    res.append(temp_res)\n",
    "\n",
    "res = torch.cat(res,dim = 1)\n",
    "print('res:', res.size())\n",
    "\n",
    "kernel = torch.rand([3, 2]) #out_channels,1])\n",
    "out = res.mm(kernel)\n",
    "print('out:', out.size())\n",
    "\n",
    "out_H = out.reshape(2, 2, 5,-1)\n",
    "out_H =out_H.permute(0, 1, 3, 2)\n",
    "print('out_H:', out_H.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test mul_out_channels, row part\n",
    "out_channels = 2\n",
    "in_H =out_L.permute(0, 1, 3, 2)\n",
    "# c.size() = batch, out_channels, col ,row\n",
    "\n",
    "\n",
    "# print('in_H:',in_H.size())\n",
    "len_row = in_H.size(3)\n",
    "b = in_H.reshape(-1,out_channels, len_row)\n",
    "# print(b.size())\n",
    "\n",
    "\n",
    "for per_index in range(b.size(1)):\n",
    "    per_channel = b[:,per_index,:]\n",
    "    print(per_channel.size())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test 4d transform matrix\n",
    "def matrix3d_matrix1d(input_matrix, kernel_size ):\n",
    "    \n",
    "    input_row = input_matrix.size(0)\n",
    "    input_col = input_matrix.size(1)\n",
    "    \n",
    "    ks = kernel_size // 2\n",
    "    trans_subrow = len(input_matrix[0]) - ks -1\n",
    "    trans_row = trans_subrow * input_row\n",
    "    trans_col = kernel_size\n",
    "    transform_maxtrix = torch.zeros([trans_row , trans_col])\n",
    "    \n",
    "    for index in range(input_row):\n",
    "        \n",
    "        ls = input_matrix[index,:]\n",
    "        \n",
    "        for i in range(ks, len(ls) - ks):\n",
    "            transform_maxtrix[i-1 + index * trans_subrow,:] = ls[i-ks: i+ks+1]\n",
    "    return transform_maxtrix\n",
    "\n",
    "def myconv1d(input_m, kernel,kernel_size):\n",
    "    # batch_size, in_channels, in_row, in_col\n",
    "    \n",
    "    temp_m = input_m.reshape(-1,input_m.size(1))\n",
    "    res = matrix3d_matrix1d(temp_m, kernel_size )\n",
    "    \n",
    "    res = res.mm(kernel)\n",
    "    res = res.reshape(input_m.size(0),-1,input_m.size(2),kernel.size(1))\n",
    "    \n",
    "    return res \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 6, 1])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### test 4d transform matrix\n",
    "\n",
    "kernel_size = 3\n",
    "output_channels = 1\n",
    "input_matrix = torch.rand(2, 6, 6, 3)\n",
    "# batch_size, in_channels, in_row, in_col\n",
    "# batch_size, in_x, in_y, in_z\n",
    "\n",
    "kernel  = torch.rand([kernel_size,output_channels])\n",
    "\n",
    "d= myconv1d(input_matrix, kernel,kernel_size)\n",
    "d.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(img, conv_filter):\n",
    "   \n",
    "    if len(img.shape)!=3 or len(conv_filter.shape)!=4:\n",
    "        print(\"卷积运算所输入的维度不符合要求\")\n",
    "        sys.exit()\n",
    "        \n",
    "    if img.shape[-1] != conv_filter.shape[-1]:\n",
    "        print(\"卷积输入图片与卷积核的通道数不一致\")\n",
    "        sys.exit()\n",
    "        \n",
    "    img_h, img_w, img_ch = img.shape\n",
    "    filter_num, filter_h, filter_w, img_ch = conv_filter.shape\n",
    "    feature_h = img_h - filter_h + 1\n",
    "    feature_w = img_w - filter_w + 1\n",
    "\n",
    "    # 初始化输出的特征图片，由于没有使用零填充，图片尺寸会减小\n",
    "    img_out = np.zeros((feature_h, feature_w, filter_num))\n",
    "    img_matrix = np.zeros((feature_h*feature_w, filter_h*filter_w*img_ch))\n",
    "    filter_matrix = np.zeros((filter_h*filter_w*img_ch, filter_num))\n",
    "    \n",
    "    # 将输入图片张量转换成矩阵形式\n",
    "    for i in range(feature_h*feature_w):\n",
    "        for j in range(img_ch):\n",
    "            img_matrix[i, j*filter_h*filter_w:(j+1)*filter_h*filter_w] = \\\n",
    "            img[np.uint16(i/feature_w):np.uint16(i/feature_w+filter_h),np.uint16(i%feature_w):np.uint16(i%feature_w+filter_w),j].reshape(filter_h*filter_w)\n",
    "    \n",
    "    # 将卷积核张量转换成矩阵形式\n",
    "    for i in range(filter_num):\n",
    "        filter_matrix[:,i] = conv_filter[i,:].reshape(filter_w*filter_h*img_ch)\n",
    "    \n",
    "    feature_matrix = np.dot(img_matrix, filter_matrix)\n",
    "    \n",
    "    for i in range(filter_num):\n",
    "        img_out[:,:,i] = feature_matrix[:,i].reshape(feature_h, feature_w)\n",
    "    \n",
    "    return img_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3045, 0.3638, 0.1190, 0.0709, 0.3345, 0.7904],\n",
       "        [0.6410, 0.8664, 0.9376, 0.1281, 0.6148, 0.0498]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8109, 0.4977, 0.8461],\n",
       "        [0.4977, 0.8461, 0.6593],\n",
       "        [0.8461, 0.6593, 0.6308],\n",
       "        [0.6593, 0.6308, 0.4467],\n",
       "        [0.2395, 0.0494, 0.8369],\n",
       "        [0.0494, 0.8369, 0.6761],\n",
       "        [0.8369, 0.6761, 0.1070],\n",
       "        [0.6761, 0.1070, 0.8767]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_maxtrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_3conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "class flatten_conv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, in_row, in_col,\n",
    "                kernel_size, stride=1, padding=0, \n",
    "                dilation=1, groups=1, bias=True, padding_mode='zeros'):\n",
    "\n",
    "        super(flatten_conv2d, self).__init__()\n",
    "        \n",
    "        self.in_row = in_row\n",
    "        self.in_col = in_col\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.L1_weight = nn.Parameter(torch.Tensor(kernel_size, out_channels))\n",
    "        self.L1_bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "\n",
    "        \n",
    "        self.L1_weight.data.uniform_(-0.1, 0.1)\n",
    "        self.L1_bias.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "#         x = self.matrix3d_matrix1d(input, self.kernel_size )\n",
    "        # See the autograd section for explanation of what happens here.\n",
    "        res = test_fun.apply(input, self.L1_weight, self.L1_bias)\n",
    "#         res = input\n",
    "        return res\n",
    "    \n",
    "    def matrix3d_matrix1d(self, input_matrix, kernel_size ):\n",
    "\n",
    "        input_row = input_matrix.size(0)\n",
    "        input_col = input_matrix.size(1)\n",
    "        \n",
    "        ks = kernel_size // 2\n",
    "        trans_subrow = len(input_matrix[0]) - ks -1\n",
    "        trans_row = trans_subrow * input_row\n",
    "        trans_col = kernel_size\n",
    "        transform_maxtrix = torch.zeros([trans_row , trans_col])\n",
    "\n",
    "        for index in range(input_row):\n",
    "\n",
    "            ls = input_matrix[index,:]\n",
    "\n",
    "            for i in range(ks, len(ls) - ks):\n",
    "                transform_maxtrix[i-1 + index * trans_subrow,:] = ls[i-ks: i+ks+1]\n",
    "        return transform_maxtrix\n",
    "\n",
    "\n",
    "#     def extra_repr(self):\n",
    "#         # (Optional)Set the extra information about this module. You can test\n",
    "#         # it by printing an object of this class.\n",
    "#         return 'in_features={}, out_features={}, bias={}'.format(\n",
    "#             self.in_features, self.out_features, self.bias is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 6, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 6, 3])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "kernel_size = 3\n",
    "output_channels = 1\n",
    "input_matrix = torch.rand(1, 2, 6, 3)\n",
    "\n",
    "f = flatten_conv2d(in_channels=2, out_channels=1, in_row=3, in_col=3,\n",
    "                kernel_size=3)\n",
    "\n",
    "r = f(input_matrix)\n",
    "r.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_fun(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, bias):\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "        print(input.size())\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "#         print(grad_output)\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        \n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        \n",
    "        return grad_input, grad_weight, grad_bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "conv1 = nn.Conv1d(2,3,kernel_size)\n",
    "input_matrix = torch.rand(2, 2, 6)\n",
    "conv1(input_matrix).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3, 1])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7209, 0.7582, 0.7923],\n",
       "         [1.2069, 1.3946, 0.9410],\n",
       "         [1.5652, 1.2715, 0.5333],\n",
       "         [0.8409, 0.9237, 1.5476]],\n",
       "\n",
       "        [[1.4687, 1.5621, 1.1674],\n",
       "         [0.8757, 0.8300, 1.1598],\n",
       "         [0.8386, 1.1064, 0.9700],\n",
       "         [0.9292, 1.1963, 1.6553]]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = c.reshape(2,-1,3)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4304],\n",
       "        [0.2370]])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = matrix3d_matrix1d(c,kernel_size)\n",
    "myconv1d(d, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myconv1d(trans_m, kernel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
