{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Function\n",
    "def get_parameter_number(net):\n",
    "    total_num = sum(p.numel() for p in net.parameters())\n",
    "    trainable_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    return {'Total': total_num, 'Trainable': trainable_num}\n",
    "\n",
    "dtype = torch.float\n",
    "\n",
    "class RandomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, size, length):\n",
    "        self.len = length\n",
    "        self.data = torch.randn(length, *size ,dtype = dtype)\n",
    "        self.label = torch.rand(1, dtype = dtype)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "        \n",
    "def Random_DataLoader():\n",
    "    input_size = [3]\n",
    "\n",
    "    train_img_loader = DataLoader(dataset=RandomDataset(input_size, length = 100),\n",
    "                         batch_size=2, shuffle=True)\n",
    "    val_img_loader =  DataLoader(dataset=RandomDataset(input_size, length = 10),\n",
    "                         batch_size=2, shuffle=False)\n",
    "\n",
    "    return train_img_loader, val_img_loader\n",
    "\n",
    "\n",
    "trainloader, valloader =  Random_DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "#      torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "#      random.seed(seed)\n",
    "#      torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, input_features, output_features, bias=True):\n",
    "        super(Linear, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.output_features = output_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(output_features, input_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(output_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.weight.data.uniform_(-0.1, 0.1)\n",
    "        if bias is not None:\n",
    "            self.bias.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # See the autograd section for explanation of what happens here.\n",
    "        return LinearFunction.apply(input, self.weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        # (Optional)Set the extra information about this module. You can test\n",
    "        # it by printing an object of this class.\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "demo_net = Linear(3,1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(demo_net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = demo_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        break\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearFunction(torch.autograd.Function):\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, bias=None):\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "        output = input.mm(weight.t())\n",
    "        \n",
    "        self.a = output.size()\n",
    "        \n",
    "        if bias is not None:\n",
    "            output += bias.unsqueeze(0).expand_as(output)\n",
    "            \n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \n",
    "#         print(grad_output.size())\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        \n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        \n",
    "#         print(ctx.needs_input_grad)\n",
    "        if ctx.needs_input_grad[0]:\n",
    "#             print('weight:',weight.size())\n",
    "            grad_input = grad_output.mm(weight)\n",
    "\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = grad_output.t().mm(input)\n",
    "\n",
    "                 \n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            \n",
    "            grad_bias = grad_output.sum(0).squeeze(0)\n",
    "            grad_bias = grad_bias.view_as(bias)\n",
    "\n",
    "            \n",
    "            \n",
    "#         print('grad_output',grad_output)\n",
    "#         print('grad_input',grad_input)\n",
    "            \n",
    "        return grad_input, grad_weight, grad_bias\n",
    "        # there backward dl/dw, dl/db\n",
    "        # and the grad_output is dl/dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-442-93d8127a4990>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdemo_net1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdemo_net2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mout_put\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdemo_net1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mout_put\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdemo_net2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_put\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-2e40e9c54f66>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# See the autograd section for explanation of what happens here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLinearFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-441-da6371268f79>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, weight, bias)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "# test two demo backward\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "in_random = torch.rand([1,3])\n",
    "label = torch.Tensor([1])\n",
    "\n",
    "demo_net1 = Linear(3,2)\n",
    "demo_net2 = Linear(2,1)\n",
    "out_put = demo_net1(in_random)\n",
    "out_put = demo_net2(out_put)\n",
    "\n",
    "loss = criterion(out_put, label)\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test 2d transform matrix\n",
    "input_matrix = torch.rand(2, 6)\n",
    "\n",
    "kernel_size = 3\n",
    "input_channels = 2\n",
    "output_channels = 2\n",
    "ks = kernel_size // 2\n",
    "per_col = len(ls) - ks -1\n",
    "transform_maxtrix = torch.zeros([per_col * 2 , kernel_size])\n",
    "fil  = torch.rand([3,output_channels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(input_matrix)):\n",
    "    ls = input_matrix[index,:]\n",
    "    for i in range(ks, len(ls) - ks):\n",
    "        transform_maxtrix[i-1 + index * per_col,:] = ls[i-ks: i+ks+1]\n",
    "\n",
    "\n",
    "output_matrix = transform_maxtrix.mm(fil)\n",
    "output = output.T\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test reshape order\n",
    "a = np.array([[[111,112],[121,122]],[[211,212],[221,222]]])\n",
    "a.reshape(2,-1, order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test conv1d kernel and input shape\n",
    "# input size = [conv_num, kernel_size * in_channels]\n",
    "# kernel matirx shape = [kernel_size * in_channels, out_channels]\n",
    "\n",
    "# test no batch_size\n",
    "a = torch.rand([3,4,5])\n",
    "# a shape = [in_channels, row, col]\n",
    "a = a.reshape([3, -1])\n",
    "# a shape = [in_channels, row * col]\n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test 4d transform matrix\n",
    "\n",
    "a = torch.rand([2,3,4,5])\n",
    "b = a.reshape(-1,a.size(3))\n",
    "len_row = a.size(3)\n",
    "# b.size() = [batch_size * x * y, z]\n",
    "# print(a)\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test 4d transform matrix\n",
    "half_kernel_size = kernel_size // 2\n",
    "kernel_size = 3\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "res = torch.empty([0])\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "        res = torch.cat([res,temp],dim = 0)  \n",
    "    # there is copy, don't warry about editing other torch\n",
    "\n",
    "res = res.reshape(-1,kernel_size)\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test 4d transform matrix\n",
    "kernel = torch.rand([3,1])\n",
    "out = res.mm(kernel)\n",
    "print(out.size())\n",
    "c = out.reshape(2,3,4,-1)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test in_channels conv1\n",
    "a = torch.rand([2,3,4,5])\n",
    "# a.size() = batch_size, in_channels, row, col\n",
    "# a.size() = batch_size, row, col, in_channels\n",
    "a =a.permute(0, 2, 3, 1)\n",
    "a.size()\n",
    "len_row = a.size(3)\n",
    "b = a.reshape(-1,len_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test in_channels conv1\n",
    "\n",
    "kernel_size = 3\n",
    "half_kernel_size = kernel_size // 2\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "res = torch.empty([0])\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "        res = torch.cat([res,temp],dim = 0)  \n",
    "    # there is copy, don't warry about editing other torch\n",
    "\n",
    "res = res.reshape(-1,kernel_size)\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test in_channels conv1\n",
    "\n",
    "kernel = torch.rand([3,1])\n",
    "out = res.mm(kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test in_channels conv1\n",
    "\n",
    "c = out.reshape(2,4,5,-1)\n",
    "c =c.permute(0, 3, 1, 2)\n",
    "\n",
    "# c.size() = batch, col, row, out_channels\n",
    "print(c.size())\n",
    "# print(out)\n",
    "# print(c)\n",
    "# out.size = [batch_size, out_channels, row, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test row conv1\n",
    "\n",
    "c =c.permute(0, 1, 3, 2)\n",
    "# a.size() = batch_size, col, , out_channels\n",
    "\n",
    "print(c.size())\n",
    "len_row = c.size(3)\n",
    "b = c.reshape(-1,len_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test 4d transform matrix\n",
    "def matrix3d_matrix1d(input_matrix, kernel_size ):\n",
    "    \n",
    "    input_row = input_matrix.size(0)\n",
    "    input_col = input_matrix.size(1)\n",
    "    \n",
    "    ks = kernel_size // 2\n",
    "    trans_subrow = len(input_matrix[0]) - ks -1\n",
    "    trans_row = trans_subrow * input_row\n",
    "    trans_col = kernel_size\n",
    "    transform_maxtrix = torch.zeros([trans_row , trans_col])\n",
    "    \n",
    "    for index in range(input_row):\n",
    "        \n",
    "        ls = input_matrix[index,:]\n",
    "        \n",
    "        for i in range(ks, len(ls) - ks):\n",
    "            transform_maxtrix[i-1 + index * trans_subrow,:] = ls[i-ks: i+ks+1]\n",
    "    return transform_maxtrix\n",
    "\n",
    "def myconv1d(input_m, kernel,kernel_size):\n",
    "    # batch_size, in_channels, in_row, in_col\n",
    "    \n",
    "    temp_m = input_m.reshape(-1,input_m.size(1))\n",
    "    res = matrix3d_matrix1d(temp_m, kernel_size )\n",
    "    \n",
    "    res = res.mm(kernel)\n",
    "    res = res.reshape(input_m.size(0),-1,input_m.size(2),kernel.size(1))\n",
    "    \n",
    "    return res \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test row conv1\n",
    "\n",
    "\n",
    "kernel_size = 3\n",
    "half_kernel_size = kernel_size // 2\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "res = torch.empty([0])\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "        res = torch.cat([res,temp],dim = 0)  \n",
    "    # there is copy, don't warry about editing other torch\n",
    "\n",
    "res = res.reshape(-1,kernel_size)\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test row conv1\n",
    "\n",
    "kernel = torch.rand([3,1])\n",
    "out = res.mm(kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test in_channels conv1\n",
    "\n",
    "d = out.reshape(2, 1, 5,-1)\n",
    "d =d.permute(0, 1, 3, 2)\n",
    "\n",
    "# c.size() = batch, col, row, out_channels\n",
    "# print(c.size())\n",
    "# print(out)\n",
    "# print(c)\n",
    "# out.size = [batch_size, out_channels, row, col]\n",
    "d.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test col conv1\n",
    "\n",
    "e =d\n",
    "# a.size() = batch_size, col, , out_channels\n",
    "\n",
    "print(e.size())\n",
    "len_row = e.size(3)\n",
    "b = e.reshape(-1,len_row)\n",
    "\n",
    "kernel_size = 3\n",
    "half_kernel_size = kernel_size // 2\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "res = torch.empty([0])\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "        res = torch.cat([res,temp],dim = 0)  \n",
    "    # there is copy, don't warry about editing other torch\n",
    "\n",
    "res = res.reshape(-1,kernel_size)\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test col conv1\n",
    "\n",
    "kernel = torch.rand([3,1])\n",
    "out = res.mm(kernel)\n",
    "\n",
    "f = out.reshape(2, 1, 2,-1)\n",
    "\n",
    "# c.size() = batch, col, row, out_channels\n",
    "# print(c.size())\n",
    "# print(out)\n",
    "# print(c)\n",
    "# out.size = [batch_size, out_channels, row, col]\n",
    "f.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test mul_out_channels, basis configure\n",
    "batch_size = 2\n",
    "in_channels = 3\n",
    "out_channels = 2\n",
    "row = 4\n",
    "col = 5\n",
    "my_input = torch.rand([batch_size,in_channels,row,col])\n",
    "L_wight_size = 3\n",
    "# a.size() = batch_size, row, col, in_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test mul_out_channels, in_channels part\n",
    "\n",
    "in_L =my_input.permute(0, 2, 3, 1)\n",
    "print('in_L:',my_input.size())\n",
    "\n",
    "len_row = in_L.size(3)\n",
    "b = in_L.reshape(-1,len_row)\n",
    "\n",
    "L_wight_size = 3\n",
    "half_L_ws = L_wight_size // 2\n",
    "index_start = half_L_ws\n",
    "index_end = len_row - half_L_ws\n",
    "\n",
    "res = []\n",
    "\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_L_ws : index+half_L_ws+1]\n",
    "        res.append(temp)\n",
    "        \n",
    "res = torch.cat(res)  \n",
    "res = res.reshape(-1,L_wight_size)\n",
    "print('res:', res.size())\n",
    "\n",
    "\n",
    "\n",
    "L_weight = torch.rand([L_wight_size, out_channels])\n",
    "out_L = res.mm(L_weight)\n",
    "\n",
    "\n",
    "out_L = out_L.reshape(2,4,5,-1)\n",
    "out_L =out_L.permute(0, 3, 1, 2)\n",
    "\n",
    "print('out_L:',out_L.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test mul_out_channels, row part\n",
    "\n",
    "in_H =out_L.permute(1, 0, 3, 2)\n",
    "# in_H shape = out_channels, batch_size, col, row\n",
    "\n",
    "print('in_H:', out_L.size())\n",
    "print('permute in_H:', in_H.size())\n",
    "\n",
    "len_row = in_H.size(3)\n",
    "\n",
    "H_wight_size = 3\n",
    "half_H_ws = H_wight_size // 2\n",
    "index_start = half_H_ws\n",
    "index_end = len_row - half_H_ws\n",
    "\n",
    "\n",
    "res = []\n",
    "for per_channel in in_H:\n",
    "    per_channel = per_channel.reshape(-1,len_row)\n",
    "    # per_channel size = batch_size, col, row\n",
    "    # per_channel size = batch_size * col, row\n",
    "    temp_res = []\n",
    "    \n",
    "    for i in per_channel:\n",
    "        for index in range(index_start, index_end):\n",
    "            temp  = i[index-half_H_ws : index+half_H_ws+1]\n",
    "            temp_res.append(temp)\n",
    "            \n",
    "    temp_res = torch.cat(temp_res,dim = 0)\n",
    "    temp_res = temp_res.reshape(-1, H_wight_size)\n",
    "    res.append(temp_res)\n",
    "\n",
    "    \n",
    "res = torch.cat(res,dim = 0)\n",
    "res = res.reshape(out_channels, -1, H_wight_size)\n",
    "\n",
    "print('res:', res.size())\n",
    "\n",
    "out_H = []\n",
    "H_weight = torch.rand([out_channels, H_wight_size]) #out_channels,1])\n",
    "\n",
    "for i in range(out_channels):\n",
    "    sub_weight = H_weight[i,:]\n",
    "    sub_weight.unsqueeze_(1)\n",
    "    sub_feature = res[i,:,:]\n",
    "    temp = sub_feature.mm(sub_weight)\n",
    "    out_H.append(temp)\n",
    "\n",
    "out_H = torch.cat(out_H,dim=0)\n",
    "# print('out:', out.size())\n",
    "out_H = out_H.reshape(out_channels, batch_size, col,-1)\n",
    "out_H =out_H.permute(1, 0, 3, 2)\n",
    "print('out_H:', out_H.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test mul_out_channels, row part\n",
    "\n",
    "in_H =out_L.permute(1, 0, 3, 2)\n",
    "# in_H shape = out_channels, batch_size, col, row\n",
    "\n",
    "print('in_H:', out_L.size())\n",
    "print('permute in_H:', in_H.size())\n",
    "\n",
    "len_row = in_H.size(3)\n",
    "\n",
    "H_wight_size = 3\n",
    "half_H_ws = H_wight_size // 2\n",
    "index_start = half_H_ws\n",
    "index_end = len_row - half_H_ws\n",
    "\n",
    "\n",
    "res = []\n",
    "for per_channel in in_H:\n",
    "    per_channel = per_channel.reshape(-1,len_row)\n",
    "    # per_channel size = batch_size, col, row\n",
    "    # per_channel size = batch_size * col, row\n",
    "    temp_res = []\n",
    "    \n",
    "    for i in per_channel:\n",
    "        for index in range(index_start, index_end):\n",
    "            temp  = i[index-half_H_ws : index+half_H_ws+1]\n",
    "            temp_res.append(temp)\n",
    "            \n",
    "    temp_res = torch.cat(temp_res,dim = 0)\n",
    "    temp_res = temp_res.reshape(-1, H_wight_size)\n",
    "    res.append(temp_res)\n",
    "\n",
    "    \n",
    "res = torch.cat(res,dim = 0)\n",
    "res = res.reshape(out_channels, -1, H_wight_size)\n",
    "\n",
    "print('res:', res.size())\n",
    "\n",
    "out_H = []\n",
    "H_weight = torch.rand([out_channels, H_wight_size]) #out_channels,1])\n",
    "\n",
    "for i in range(out_channels):\n",
    "    sub_weight = H_weight[i,:]\n",
    "    sub_weight.unsqueeze_(1)\n",
    "    sub_feature = res[i,:,:]\n",
    "    temp = sub_feature.mm(sub_weight)\n",
    "    out_H.append(temp)\n",
    "\n",
    "out_H = torch.cat(out_H,dim=0)\n",
    "# print('out_H:', out_H.size())\n",
    "out_H = out_H.reshape(out_channels, batch_size, col,-1)\n",
    "out_H =out_H.permute(1, 0, 3, 2)\n",
    "print('out_H:', out_H.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test mul_out_channels, col part\n",
    "new_row = out_H.size(2)\n",
    "in_V =out_H.permute(1, 0, 2, 3)\n",
    "# in_V shape = out_channels, batch_size, row, col \n",
    "\n",
    "print('in_V:', out_H.size())\n",
    "print('permute in_V:', in_V.size())\n",
    "\n",
    "len_row = in_V.size(3)\n",
    "\n",
    "V_wight_size = 3\n",
    "half_V_ws = V_wight_size // 2\n",
    "index_start = half_V_ws\n",
    "index_end = len_row - half_V_ws\n",
    "\n",
    "\n",
    "res = []\n",
    "for per_channel in in_V:\n",
    "    per_channel = per_channel.reshape(-1,len_row)\n",
    "    # per_channel size = batch_size, row, col\n",
    "    # per_channel size = batch_size * row, col\n",
    "    temp_res = []\n",
    "    \n",
    "    for i in per_channel:\n",
    "        for index in range(index_start, index_end):\n",
    "            temp  = i[index-half_V_ws : index+half_V_ws+1]\n",
    "            temp_res.append(temp)\n",
    "            \n",
    "    temp_res = torch.cat(temp_res,dim = 0)\n",
    "    temp_res = temp_res.reshape(-1, V_wight_size)\n",
    "    res.append(temp_res)\n",
    "\n",
    "    \n",
    "res = torch.cat(res,dim = 0)\n",
    "res = res.reshape(out_channels, -1, V_wight_size)\n",
    "\n",
    "print('res:', res.size())\n",
    "\n",
    "out_V = []\n",
    "V_weight = torch.rand([out_channels, V_wight_size]) #out_channels,1])\n",
    "\n",
    "for i in range(out_channels):\n",
    "    sub_weight = V_weight[i,:]\n",
    "    sub_weight.unsqueeze_(1)\n",
    "    sub_feature = res[i,:,:]\n",
    "    temp = sub_feature.mm(sub_weight)\n",
    "    out_V.append(temp)\n",
    "\n",
    "out_V = torch.cat(out_V,dim=0)\n",
    "# print('out_V:', out_V.size())\n",
    "out_V = out_V.reshape(out_channels, batch_size, new_row,-1)\n",
    "out_V =out_V.permute(1, 0, 2, 3)\n",
    "print('out_V:', out_V.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test mul_out_channels class\n",
    "\n",
    "class test_mul_out_channels():\n",
    "    def __init__(self, out_channels):\n",
    "        self.row = 0\n",
    "        self.col = 0\n",
    "        self.out_channels = out_channels\n",
    "#         self.in_channels = in_channels\n",
    "        self.batch_size =0\n",
    "        \n",
    "    def full_conv(self,input):\n",
    "        self.batch_size = input.size(0)\n",
    "        self.in_channels = input.size(1)\n",
    "        self.row = input.size(2)\n",
    "        self.col = input.size(3)\n",
    "        \n",
    "        in_L =input.permute(0, 2, 3, 1)\n",
    "        out_L = self.conv1d_L(in_L, wight_size = self.in_channels)\n",
    "        out_L =out_L.permute(0, 3, 1, 2)\n",
    "        print('out_L:', out_L.size())\n",
    "        \n",
    "        \n",
    "        \n",
    "        in_H =out_L.permute(1, 0, 3, 2)\n",
    "        out_H = self.conv1d_VH(in_H, wight_size =3 )\n",
    "        out_H =out_H.permute(1, 0, 3, 2)\n",
    "        print('out_H:', out_H.size())\n",
    "\n",
    "        in_V =out_H.permute(1, 0, 2, 3)\n",
    "        out_V = self.conv1d_VH(in_V, wight_size =3 )\n",
    "        out_V =out_V.permute(1, 0, 2, 3)\n",
    "        print('out_V:', out_V.size())\n",
    "        return out_V\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    def conv1d_L(self, in_matrix, wight_size):\n",
    "        \n",
    "\n",
    "#         print('in_L:',my_input.size())\n",
    "\n",
    "        len_row = in_matrix.size(3)\n",
    "        b = in_matrix.reshape(-1,len_row)\n",
    "\n",
    "        L_wight_size = wight_size\n",
    "        half_L_ws = L_wight_size // 2\n",
    "        index_start = half_L_ws\n",
    "        index_end = len_row - half_L_ws\n",
    "\n",
    "        res = []\n",
    "\n",
    "        for i in b:\n",
    "            for index in range(index_start, index_end):\n",
    "                temp  = i[index-half_L_ws : index+half_L_ws+1]\n",
    "                res.append(temp)\n",
    "\n",
    "        res = torch.cat(res)  \n",
    "        res = res.reshape(-1,L_wight_size)\n",
    "\n",
    "        print(res.size())\n",
    "\n",
    "        L_weight = torch.rand([L_wight_size, self.out_channels])\n",
    "        out_L = res.mm(L_weight)\n",
    "        out_L = out_L.reshape(self.batch_size , self.row , self.col, -1)\n",
    "\n",
    "        return out_L\n",
    "        \n",
    "        \n",
    "        \n",
    "    def conv1d_VH(self, in_matrix, wight_size):\n",
    "\n",
    "        out_shape = list(in_matrix.size())\n",
    "        out_shape = out_shape[:-1] + [-1]\n",
    "        in_V =in_matrix\n",
    "\n",
    "        len_row = in_V.size(3)\n",
    "        \n",
    "        V_wight_size = wight_size\n",
    "        half_V_ws = V_wight_size // 2\n",
    "        index_start = half_V_ws\n",
    "        index_end = len_row - half_V_ws\n",
    "\n",
    "\n",
    "        res = []\n",
    "        for per_channel in in_V:\n",
    "            per_channel = per_channel.reshape(-1,len_row)\n",
    "            # per_channel size = batch_size, row, col\n",
    "            # per_channel size = batch_size * row, col\n",
    "            temp_res = []\n",
    "\n",
    "            for i in per_channel:\n",
    "                for index in range(index_start, index_end):\n",
    "                    temp  = i[index-half_V_ws : index+half_V_ws+1]\n",
    "                    temp_res.append(temp)\n",
    "\n",
    "            temp_res = torch.cat(temp_res,dim = 0)\n",
    "            temp_res = temp_res.reshape(-1, V_wight_size)\n",
    "            res.append(temp_res)\n",
    "\n",
    "\n",
    "        res = torch.cat(res,dim = 0)\n",
    "        res = res.reshape(self.out_channels, -1, V_wight_size)\n",
    "\n",
    "#         print('res:', res.size())\n",
    "\n",
    "        out_V = []\n",
    "        V_weight = torch.rand([self.out_channels, V_wight_size]) #out_channels,1])\n",
    "\n",
    "        for i in range(out_channels):\n",
    "            sub_weight = V_weight[i,:]\n",
    "            sub_weight.unsqueeze_(1)\n",
    "            sub_feature = res[i,:,:]\n",
    "            temp = sub_feature.mm(sub_weight)\n",
    "            out_V.append(temp)\n",
    "\n",
    "        out_V = torch.cat(out_V,dim=0)\n",
    "        # print('out_V:', out_V.size())\n",
    "        out_V = out_V.reshape(*out_shape)\n",
    "        return out_V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 5])\n",
      "torch.Size([40, 3])\n",
      "out_L: torch.Size([2, 2, 4, 5])\n",
      "out_H: torch.Size([2, 2, 2, 5])\n",
      "out_V: torch.Size([2, 2, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2, 3])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#test mul_out_channels class\n",
    "\n",
    "batch_size = 2\n",
    "in_channels = 3\n",
    "out_channels = 2\n",
    "row = 4\n",
    "col = 5\n",
    "my_input = torch.rand([batch_size,in_channels,row,col])\n",
    "print(my_input.size())\n",
    "\n",
    "\n",
    "S = test_mul_out_channels(out_channels =2)\n",
    "c = S.full_conv(my_input )\n",
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test Module class\n",
    "class flatten_conv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, in_row, in_col,\n",
    "                kernel_size, stride=1, padding=0, \n",
    "                dilation=1, groups=1, bias=True, padding_mode='zeros'):\n",
    "\n",
    "        super(flatten_conv2d, self).__init__()\n",
    "        \n",
    "#         self.in_row = in_row\n",
    "#         self.in_col = in_col\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "#         self.kernel_size = kernel_size\n",
    "        wight_size = self.in_channels\n",
    "        self.L1_weight = nn.Parameter(torch.Tensor(in_channels, out_channels))\n",
    "        self.L1_bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        \n",
    "        self.V1_weight = nn.Parameter(torch.Tensor(out_channels, kernel_size))\n",
    "        self.V1_bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        \n",
    "        self.H1_weight = nn.Parameter(torch.Tensor(out_channels, kernel_size))\n",
    "        self.H1_bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "\n",
    "        \n",
    "        self.L1_weight.data.uniform_(-0.1, 0.1)\n",
    "        self.L1_bias.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "        self.V1_weight.data.uniform_(-0.1, 0.1)\n",
    "        self.V1_bias.data.uniform_(-0.1, 0.1)\n",
    "               \n",
    "        self.H1_weight.data.uniform_(-0.1, 0.1)\n",
    "        self.H1_bias.data.uniform_(-0.1, 0.1)\n",
    "         \n",
    "    def forward(self, input):\n",
    "#         x = self.matrix3d_matrix1d(input, self.kernel_size )\n",
    "        # See the autograd section for explanation of what happens here.\n",
    "#         res = test_fun.apply(input, self.L1_weight, self.L1_bias)\n",
    "        \n",
    "        out_L = conv1d_L.apply(input, self.L1_weight, self.L1_bias)\n",
    "#         print('out_L:', out_L.size())\n",
    "        \n",
    "        out_V = conv1d_V.apply(out_L, self.V1_weight, self.V1_bias)\n",
    "#         print('out_V:', out_V.size())\n",
    "        \n",
    "        out_H = conv1d_H.apply(out_V, self.H1_weight, self.H1_bias)\n",
    "#         print('out_H:', out_H.size())\n",
    "        \n",
    "        return out_H\n",
    "\n",
    "#     def extra_repr(self):\n",
    "#         # (Optional)Set the extra information about this module. You can test\n",
    "#         # it by printing an object of this class.\n",
    "#         return 'in_features={}, out_features={}, bias={}'.format(\n",
    "#             self.in_features, self.out_features, self.bias is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 3])"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#test mul_out_channels class\n",
    "\n",
    "batch_size = 2\n",
    "in_channels = 3\n",
    "out_channels = 3\n",
    "row = 4\n",
    "col = 5\n",
    "kernel_size = 3\n",
    "my_input = torch.rand([batch_size,in_channels,row,col])\n",
    "\n",
    "S = flatten_conv2d(in_channels= in_channels, \n",
    "                   out_channels= out_channels , \n",
    "                   in_row=row, in_col=col, kernel_size=kernel_size)\n",
    "\n",
    "my_output = S(my_input )\n",
    "my_output.size()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(input_shape, weight_shape):\n",
    "    batch_size, channels, row, col = list(input_shape)\n",
    "    _, wight_size = list(weight_shape)\n",
    "    \n",
    "    half_ws = wight_size // 2\n",
    "    windows_per = col - wight_size + 1\n",
    "    \n",
    "    new_col = windows_per\n",
    "    \n",
    "    XC_row = batch_size * row * windows_per\n",
    "    XC_col = wight_size\n",
    "    XC_shape = [XC_row, XC_col]\n",
    "\n",
    "    output_shape = [batch_size, channels, row, new_col]\n",
    "    return output_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def im2col(input, weight_shape):\n",
    "\n",
    "    in_matrix =input\n",
    "    out_channels, wight_size = list(weight_shape)\n",
    "    \n",
    "    XC_shape = [out_channels, -1, wight_size]\n",
    "\n",
    "    len_row = in_matrix.size(3)\n",
    "    half_ws = wight_size // 2\n",
    "    index_start = half_ws\n",
    "    index_end = len_row - half_ws\n",
    "\n",
    "    XC = []\n",
    "    for per_channel in in_matrix:\n",
    "        per_channel = per_channel.reshape(-1,len_row)\n",
    "\n",
    "        temp_res = []\n",
    "\n",
    "        for i in per_channel:\n",
    "            for index in range(index_start, index_end):\n",
    "                temp  = i[index-half_ws : index+half_ws+1]\n",
    "                temp_res.append(temp)\n",
    "\n",
    "        temp_res = torch.cat(temp_res,dim = 0)\n",
    "        temp_res = temp_res.reshape(-1, wight_size)\n",
    "        XC.append(temp_res)\n",
    "\n",
    "    XC = torch.cat(XC,dim = 0)\n",
    "    XC = XC.reshape(*XC_shape)\n",
    "    return XC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class conv1d_H(torch.autograd.Function):\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, bias):\n",
    "\n",
    "        out_channels, _ = list(weight.size())\n",
    "        \n",
    "        \n",
    "        in_matrix =input.permute(1, 0, 2, 3)\n",
    "        out_shape = get_shape(in_matrix.size(), weight.size())\n",
    "        \n",
    "        \n",
    "        XC = im2col(in_matrix, weight.size())\n",
    "        out_matrix = XC_mul_WC(XC, weight, bias)\n",
    "        \n",
    "        out_matrix = out_matrix.reshape(*out_shape)\n",
    "        out_matrix =out_matrix.permute(1, 0, 2, 3)\n",
    "        \n",
    "        ctx.save_for_backward(XC, weight, bias)\n",
    "        \n",
    "        return out_matrix\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \n",
    "#         print('conv1d_H:',ctx.needs_input_grad)\n",
    "        XC, weight, bias = ctx.saved_tensors\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        out_channels, wight_size = list(weight.size())\n",
    "        \n",
    "        dY = grad_output.permute(1, 0, 2, 3)\n",
    "        # out_channels, batch_size, row, col\n",
    "\n",
    "        \n",
    "        if ctx.needs_input_grad[0]:\n",
    "            \n",
    "            grad_input = []\n",
    "            \n",
    "\n",
    "            weight_flip = torch.flip(weight, dims = [1])\n",
    "\n",
    "            pad_shape = get_pad_shape(dY.size(), weight.size())\n",
    "            pad = torch.zeros(*pad_shape)\n",
    "            dY_pad = torch.cat([pad, dY, pad],dim = 3)\n",
    "            dYC_pad =  im2col(dY_pad, weight.size())\n",
    "            \n",
    "            \n",
    "            out_shape = get_shape(dY_pad.size(), weight.size())\n",
    "            \n",
    "            grad_input = XC_mul_WC(dYC_pad, weight_flip)\n",
    "            grad_input = grad_input.reshape(*out_shape)\n",
    "            grad_input =grad_input.permute(1, 0, 2, 3)   \n",
    "            \n",
    "\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = []\n",
    "\n",
    "            for i in range(out_channels):\n",
    "                sub_XC = XC[i,:,:]\n",
    "                sub_dY = dY[i,:,:,:]\n",
    "                sub_dY = sub_dY.reshape(-1,1)\n",
    "                grad_weight.append(sub_XC.t().mm(sub_dY))\n",
    "\n",
    "            grad_weight = torch.cat(grad_weight)\n",
    "            grad_weight = grad_weight.reshape(out_channels, wight_size)\n",
    "            \n",
    "\n",
    "            \n",
    "        if ctx.needs_input_grad[2]:\n",
    "            \n",
    "            grad_bias = dY.reshape(out_channels,-1)\n",
    "            grad_bias = grad_bias.sum(dim = 1)\n",
    "            grad_bias = grad_bias.view_as(bias)\n",
    "            \n",
    "            \n",
    "#         print('H grad_input',grad_input)\n",
    "#         print('H grad_weight',grad_weight)\n",
    "#         print('H grad_bias',grad_bias)\n",
    "\n",
    "        return grad_input, grad_weight, grad_bias\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_shape(input_shape, weight_shape):\n",
    "    out_channels, batch_size, row, col = list(input_shape)\n",
    "    _, wight_size = list(weight_shape)\n",
    "    pad_shape = [out_channels, batch_size, row , wight_size - 1]\n",
    "    \n",
    "    return pad_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XC_mul_WC(XC, weight, bias = None):\n",
    "            \n",
    "    out_matrix = []\n",
    "    out_channels = weight.size(0)\n",
    "    for i in range(out_channels):\n",
    "        sub_weight = weight[i,:]\n",
    "        sub_weight.unsqueeze_(1)\n",
    "        sub_feature = XC[i,:,:]\n",
    "        temp = sub_feature.mm(sub_weight)\n",
    "        \n",
    "        if bias is not None:\n",
    "            sub_bias = bias[i]\n",
    "            temp +=  sub_bias\n",
    "\n",
    "        out_matrix.append(temp)\n",
    "\n",
    "    out_matrix = torch.cat(out_matrix,dim=0)\n",
    "    return out_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv1d_V(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, bias):\n",
    "        \n",
    "        out_channels, _ = list(weight.size())\n",
    "        \n",
    "        \n",
    "        in_matrix =input.permute(1, 0, 3, 2)\n",
    "        out_shape = get_shape(in_matrix.size(), weight.size())\n",
    "        \n",
    "        \n",
    "        XC = im2col(in_matrix, weight.size())\n",
    "        out_matrix = XC_mul_WC(XC, weight, bias)\n",
    "        \n",
    "        out_matrix = out_matrix.reshape(*out_shape)\n",
    "        out_matrix =out_matrix.permute(1, 0, 3, 2)\n",
    "        \n",
    "        ctx.save_for_backward(XC, weight, bias)\n",
    "        \n",
    "        return out_matrix\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \n",
    "#         print('conv1d_H:',ctx.needs_input_grad)\n",
    "        ### init\n",
    "        XC, weight, bias = ctx.saved_tensors\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        out_channels, wight_size = list(weight.size())\n",
    "        \n",
    "        dY = grad_output.permute(1, 0, 3, 2)\n",
    "    \n",
    " \n",
    "        if ctx.needs_input_grad[0]:\n",
    "            \n",
    "            grad_input = []\n",
    "            \n",
    "\n",
    "            weight_flip = torch.flip(weight, dims = [1])\n",
    "            \n",
    "            pad_shape = get_pad_shape(dY.size(), weight.size())\n",
    "            pad = torch.zeros(*pad_shape)\n",
    "            \n",
    "            dY_pad = torch.cat([pad, dY, pad],dim = 3)\n",
    "            dYC_pad =  im2col(dY_pad, weight.size())\n",
    "            \n",
    "            out_shape = get_shape(dY_pad.size(), weight.size())\n",
    "            \n",
    "            grad_input = XC_mul_WC(dYC_pad, weight_flip)\n",
    "            grad_input = grad_input.reshape(*out_shape)\n",
    "            grad_input =grad_input.permute(1, 0, 3, 2)\n",
    "            \n",
    "\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = []\n",
    "\n",
    "            for i in range(out_channels):\n",
    "                sub_XC = XC[i,:,:]\n",
    "                sub_dY = dY[i,:,:,:]\n",
    "                sub_dY = sub_dY.reshape(-1,1)\n",
    "                grad_weight.append(sub_XC.t().mm(sub_dY))\n",
    "\n",
    "            grad_weight = torch.cat(grad_weight)\n",
    "            grad_weight = grad_weight.reshape(out_channels, wight_size)\n",
    "            \n",
    "\n",
    "            \n",
    "        if ctx.needs_input_grad[2]:\n",
    "            \n",
    "            grad_bias = dY.reshape(out_channels,-1)\n",
    "            grad_bias = grad_bias.sum(dim = 1)\n",
    "            grad_bias = grad_bias.view_as(bias)\n",
    "            \n",
    "#         print('V grad_input',grad_input)\n",
    "#         print('V grad_weight',grad_weight)\n",
    "#         print('V grad_bias',grad_bias)\n",
    "\n",
    "        return grad_input, grad_weight, grad_bias\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv1d_L(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, bias):\n",
    "        \n",
    "        in_matrix =input.permute(0, 2, 3, 1)\n",
    "        \n",
    "        out_shape = list(in_matrix.size())\n",
    "        out_shape = out_shape[:-1] + [-1]\n",
    "        \n",
    "        \n",
    "        channels = in_matrix.size(3)\n",
    "\n",
    "        XC = in_matrix.reshape(-1,channels)\n",
    "        \n",
    "        out_matrix = XC.mm(weight)\n",
    "        out_matrix = out_matrix + bias\n",
    "        out_matrix = out_matrix.reshape(*out_shape)\n",
    "        out_matrix = out_matrix.permute(0, 3, 1, 2)\n",
    "        \n",
    "        ctx.save_for_backward(XC, weight, bias)\n",
    "\n",
    "        return out_matrix\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "#         print('conv1d_L:',ctx.needs_input_grad)\n",
    "\n",
    "        XC, weight, bias = ctx.saved_tensors\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        in_channels, out_channels = list(weight.size())\n",
    "        \n",
    "        dY = grad_output.permute(0, 2, 3, 1)\n",
    "        dYC = dY.reshape(-1,out_channels)\n",
    "        \n",
    "        if ctx.needs_input_grad[0]:\n",
    "        \n",
    "            out_shape = list(dY.size())\n",
    "            out_shape = out_shape[:-1] + [-1]\n",
    "\n",
    "            grad_input = dYC.mm(weight.t())\n",
    "            \n",
    "            grad_input = grad_input.reshape(*out_shape)\n",
    "            grad_input =grad_input.permute(0, 3, 1, 2)\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = XC.t().mm(dYC)\n",
    "                                \n",
    "        if ctx.needs_input_grad[2]:\n",
    "            grad_bias = dYC.sum(dim = 0)\n",
    "            grad_bias = grad_bias.view_as(bias)\n",
    "            \n",
    "        return grad_input, grad_weight, grad_bias\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test Module class\n",
    "class flatten_conv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, in_row, in_col,\n",
    "                kernel_size, stride=1, padding=0, \n",
    "                dilation=1, groups=1, bias=True, padding_mode='zeros'):\n",
    "\n",
    "        super(flatten_conv2d, self).__init__()\n",
    "        \n",
    "#         self.in_row = in_row\n",
    "#         self.in_col = in_col\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "#         self.kernel_size = kernel_size\n",
    "        wight_size = self.in_channels\n",
    "        self.L1_weight = nn.Parameter(torch.Tensor(in_channels, out_channels))\n",
    "        self.L1_bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        \n",
    "        self.V1_weight = nn.Parameter(torch.Tensor(out_channels, kernel_size))\n",
    "        self.V1_bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        \n",
    "        self.H1_weight = nn.Parameter(torch.Tensor(out_channels, kernel_size))\n",
    "        self.H1_bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "\n",
    "        self.L2_weight = nn.Parameter(torch.Tensor(out_channels, out_channels))\n",
    "        self.L2_bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        \n",
    "        self.V2_weight = nn.Parameter(torch.Tensor(out_channels, kernel_size))\n",
    "        self.V2_bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        \n",
    "        self.H2_weight = nn.Parameter(torch.Tensor(out_channels, kernel_size))\n",
    "        self.H2_bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.L1_weight.data.uniform_(-0.1, 0.1)\n",
    "        self.L1_bias.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "        self.V1_weight.data.uniform_(-0.1, 0.1)\n",
    "        self.V1_bias.data.uniform_(-0.1, 0.1)\n",
    "               \n",
    "        self.H1_weight.data.uniform_(-0.1, 0.1)\n",
    "        self.H1_bias.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "        self.L2_weight.data.uniform_(-0.1, 0.1)\n",
    "        self.L2_bias.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "        \n",
    "        self.V2_weight.data.uniform_(-0.1, 0.1)\n",
    "        self.V2_bias.data.uniform_(-0.1, 0.1)\n",
    "               \n",
    "        self.H2_weight.data.uniform_(-0.1, 0.1)\n",
    "        self.H2_bias.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "        self.pad = torch.nn.ReflectionPad2d(1)\n",
    "         \n",
    "    def forward(self, input):\n",
    "#         x = self.matrix3d_matrix1d(input, self.kernel_size )\n",
    "        # See the autograd section for explanation of what happens here.\n",
    "#         res = test_fun.apply(input, self.L1_weight, self.L1_bias)\n",
    "        \n",
    "        out_L1 = conv1d_L.apply(input, self.L1_weight, self.L1_bias)\n",
    "        print('out_L1:', out_L1.size())\n",
    "        \n",
    "        out_V1 = conv1d_V.apply(out_L1, self.V1_weight, self.V1_bias)\n",
    "        print('out_V1:', out_V1.size())\n",
    "        \n",
    "        out_H1 = conv1d_H.apply(out_V1, self.H1_weight, self.H1_bias)\n",
    "        print('out_H1:', out_H1.size())\n",
    "        \n",
    "        out_L2 = conv1d_L.apply(out_H1, self.L2_weight, self.L2_bias)\n",
    "        print('out_L2:', out_L2.size())\n",
    "        \n",
    "        out_L2 = self.pad(out_L2)\n",
    "        \n",
    "        out_V2 = conv1d_V.apply(out_L2, self.V2_weight, self.V2_bias)\n",
    "        print('out_V2:', out_V2.size())\n",
    "        \n",
    "        out_H2 = conv1d_H.apply(out_V2, self.H2_weight, self.H2_bias)\n",
    "        print('out_H2:', out_H2.size())\n",
    "        return out_H2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_L1: torch.Size([2, 6, 10, 13])\n",
      "out_V1: torch.Size([2, 6, 8, 13])\n",
      "out_H1: torch.Size([2, 6, 8, 11])\n",
      "out_L2: torch.Size([2, 6, 8, 11])\n",
      "out_V2: torch.Size([2, 6, 8, 13])\n",
      "out_H2: torch.Size([2, 6, 8, 11])\n"
     ]
    }
   ],
   "source": [
    "#test mul_out_channels backward\n",
    "# ctx.needs_input_grad\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "batch_size = 2\n",
    "in_channels = 3\n",
    "out_channels = 6\n",
    "row = 10\n",
    "col = 13\n",
    "kernel_size = 3\n",
    "torch.manual_seed(0)\n",
    "my_input = torch.rand([batch_size,in_channels,row,col])\n",
    "\n",
    "S = flatten_conv2d(in_channels= in_channels, \n",
    "                   out_channels= out_channels , \n",
    "                   in_row=row, in_col=col, kernel_size=kernel_size)\n",
    "\n",
    "my_output = S(my_input )\n",
    "label = torch.ones_like(my_output)\n",
    "\n",
    "\n",
    "loss = criterion(my_output, label)\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 12, 15])"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = torch.nn.ReflectionPad2d(1)\n",
    "my_input = torch.rand([batch_size,in_channels,row,col])\n",
    "pri\n",
    "pad(my_input).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "conv1 = nn.Conv1d(2,3,kernel_size)\n",
    "input_matrix = torch.rand(2, 2, 6)\n",
    "conv1(input_matrix).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        print(ctx.needs_input_grad)\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = grad_output.mm(weight)\n",
    "\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = grad_output.t().mm(input)\n",
    "\n",
    "                 \n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            \n",
    "            grad_bias = grad_output.sum(0).squeeze(0)\n",
    "            grad_bias = grad_bias.view_as(bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c.reshape(2,-1,3)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = matrix3d_matrix1d(c,kernel_size)\n",
    "myconv1d(d, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myconv1d(trans_m, kernel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
