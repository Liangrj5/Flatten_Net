{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Function\n",
    "def get_parameter_number(net):\n",
    "    total_num = sum(p.numel() for p in net.parameters())\n",
    "    trainable_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    return {'Total': total_num, 'Trainable': trainable_num}\n",
    "\n",
    "dtype = torch.float\n",
    "\n",
    "class RandomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, size, length):\n",
    "        self.len = length\n",
    "        self.data = torch.randn(length, *size ,dtype = dtype)\n",
    "        self.label = torch.rand(1, dtype = dtype)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "        \n",
    "def Random_DataLoader():\n",
    "    input_size = [3]\n",
    "\n",
    "    train_img_loader = DataLoader(dataset=RandomDataset(input_size, length = 100),\n",
    "                         batch_size=2, shuffle=True)\n",
    "    val_img_loader =  DataLoader(dataset=RandomDataset(input_size, length = 10),\n",
    "                         batch_size=2, shuffle=False)\n",
    "\n",
    "    return train_img_loader, val_img_loader\n",
    "\n",
    "\n",
    "trainloader, valloader =  Random_DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, bias=None):\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "        output = input.mm(weight.t())\n",
    "        print(input.size())\n",
    "        print(weight.size())\n",
    "        print(output.size())\n",
    "        \n",
    "        if bias is not None:\n",
    "            output += bias.unsqueeze(0).expand_as(output)\n",
    "            \n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "#         print(grad_output)\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        \n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "\n",
    "        \n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = grad_output.mm(weight)\n",
    "\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = grad_output.t().mm(input)\n",
    "\n",
    "                 \n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            \n",
    "            grad_bias = grad_output.sum(0).squeeze(0)\n",
    "            grad_bias = grad_bias.view_as(bias)\n",
    "#         print(\"*\" * 40)\n",
    "#         print(bias.size())\n",
    "#         print(grad_weight.size())\n",
    "#         print(grad_bias.size())\n",
    "#         print(\"*\" * 40)\n",
    "        return grad_input, grad_weight, grad_bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, input_features, output_features, bias=True):\n",
    "        super(Linear, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.output_features = output_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(output_features, input_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(output_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.weight.data.uniform_(-0.1, 0.1)\n",
    "        if bias is not None:\n",
    "            self.bias.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # See the autograd section for explanation of what happens here.\n",
    "        return LinearFunction.apply(input, self.weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        # (Optional)Set the extra information about this module. You can test\n",
    "        # it by printing an object of this class.\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([2, 1])\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "demo_net = Linear(3,1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(demo_net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        \n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = demo_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        break\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test 2d transform matrix\n",
    "input_matrix = torch.rand(2, 6)\n",
    "\n",
    "kernel_size = 3\n",
    "input_channels = 2\n",
    "output_channels = 2\n",
    "ks = kernel_size // 2\n",
    "per_col = len(ls) - ks -1\n",
    "transform_maxtrix = torch.zeros([per_col * 2 , kernel_size])\n",
    "fil  = torch.rand([3,output_channels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index in range(len(input_matrix)):\n",
    "    ls = input_matrix[index,:]\n",
    "    for i in range(ks, len(ls) - ks):\n",
    "        transform_maxtrix[i-1 + index * per_col,:] = ls[i-ks: i+ks+1]\n",
    "\n",
    "\n",
    "output_matrix = transform_maxtrix.mm(fil)\n",
    "output = output.T\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[111, 121, 112, 122],\n",
       "       [211, 221, 212, 222]])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### test reshape order\n",
    "a = np.array([[[111,112],[121,122]],[[211,212],[221,222]]])\n",
    "a.reshape(2,-1, order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test reshape order\n",
    "a = torch.rand([2,3,4,5])\n",
    "b = a.reshape(-1,a.size(3))\n",
    "len_row = a.size(3)\n",
    "# b.size() = [batch_size * x * y, z]\n",
    "# print(a)\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([72, 3])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### test 4d transform matrix\n",
    "half_kernel_size = kernel_size // 2\n",
    "kernel_size = 3\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "res = torch.empty([0])\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "        res = torch.cat([res,temp],dim = 0)  \n",
    "    # there is copy, don't warry about editing other torch\n",
    "\n",
    "res = res.reshape(-1,kernel_size)\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 3, 4, -1]' is invalid for input of size 40",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-485-96e6698d5769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 3, 4, -1]' is invalid for input of size 40"
     ]
    }
   ],
   "source": [
    "### test 4d transform matrix\n",
    "kernel = torch.rand([3,1])\n",
    "out = res.mm(kernel)\n",
    "print(out.size())\n",
    "c = out.reshape(2,3,4,-1)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test in_channels conv1\n",
    "a = torch.rand([2,3,4,5])\n",
    "# a.size() = batch_size, in_channels, row, col\n",
    "# a.size() = batch_size, col, row, in_channels\n",
    "a =a.permute(0, 2, 3, 1)\n",
    "a.size()\n",
    "len_row = a.size(3)\n",
    "b = a.reshape(-1,len_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5, 3])"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 3])"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test in_channels conv1\n",
    "\n",
    "kernel_size = 3\n",
    "half_kernel_size = kernel_size // 2\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "res = torch.empty([0])\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "        res = torch.cat([res,temp],dim = 0)  \n",
    "    # there is copy, don't warry about editing other torch\n",
    "\n",
    "res = res.reshape(-1,kernel_size)\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test 4d transform matrix\n",
    "kernel = torch.rand([3,2])\n",
    "out = res.mm(kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 4, 5])\n",
      "tensor([[1.2781, 1.4749],\n",
      "        [0.9388, 1.1743],\n",
      "        [0.4689, 0.4788],\n",
      "        [0.7503, 0.9506],\n",
      "        [0.5598, 0.5065],\n",
      "        [0.6000, 0.6779],\n",
      "        [0.5866, 0.7957],\n",
      "        [0.7180, 0.9033],\n",
      "        [0.6443, 0.5941],\n",
      "        [0.9016, 0.9318],\n",
      "        [0.5196, 0.6592],\n",
      "        [0.5600, 0.6259],\n",
      "        [0.4484, 0.5688],\n",
      "        [0.8915, 1.1480],\n",
      "        [0.7994, 0.9523],\n",
      "        [0.5033, 0.8063],\n",
      "        [0.8639, 0.9884],\n",
      "        [0.7660, 0.9626],\n",
      "        [0.5497, 0.6289],\n",
      "        [0.6807, 0.8147],\n",
      "        [0.8972, 0.9620],\n",
      "        [0.8622, 1.0136],\n",
      "        [0.3166, 0.4414],\n",
      "        [0.5248, 0.7221],\n",
      "        [0.9208, 1.2434],\n",
      "        [0.5474, 0.5646],\n",
      "        [0.4990, 0.5894],\n",
      "        [0.4190, 0.4914],\n",
      "        [0.7702, 0.9438],\n",
      "        [0.2719, 0.2951],\n",
      "        [0.7868, 0.9340],\n",
      "        [0.6308, 0.8879],\n",
      "        [0.4212, 0.5223],\n",
      "        [0.7306, 0.8741],\n",
      "        [1.0962, 1.1369],\n",
      "        [0.6293, 0.5639],\n",
      "        [0.3491, 0.5460],\n",
      "        [0.8342, 1.0021],\n",
      "        [1.0793, 1.3323],\n",
      "        [0.5691, 0.5856]])\n",
      "tensor([[[[1.2781, 0.9388, 0.4689, 0.7503, 0.5598],\n",
      "          [0.6000, 0.5866, 0.7180, 0.6443, 0.9016],\n",
      "          [0.5196, 0.5600, 0.4484, 0.8915, 0.7994],\n",
      "          [0.5033, 0.8639, 0.7660, 0.5497, 0.6807]],\n",
      "\n",
      "         [[1.4749, 1.1743, 0.4788, 0.9506, 0.5065],\n",
      "          [0.6779, 0.7957, 0.9033, 0.5941, 0.9318],\n",
      "          [0.6592, 0.6259, 0.5688, 1.1480, 0.9523],\n",
      "          [0.8063, 0.9884, 0.9626, 0.6289, 0.8147]]],\n",
      "\n",
      "\n",
      "        [[[0.8972, 0.8622, 0.3166, 0.5248, 0.9208],\n",
      "          [0.5474, 0.4990, 0.4190, 0.7702, 0.2719],\n",
      "          [0.7868, 0.6308, 0.4212, 0.7306, 1.0962],\n",
      "          [0.6293, 0.3491, 0.8342, 1.0793, 0.5691]],\n",
      "\n",
      "         [[0.9620, 1.0136, 0.4414, 0.7221, 1.2434],\n",
      "          [0.5646, 0.5894, 0.4914, 0.9438, 0.2951],\n",
      "          [0.9340, 0.8879, 0.5223, 0.8741, 1.1369],\n",
      "          [0.5639, 0.5460, 1.0021, 1.3323, 0.5856]]]])\n"
     ]
    }
   ],
   "source": [
    "# out = out.T\n",
    "\n",
    "# print(out.size())\n",
    "c = out.reshape(2,4,5,-1)\n",
    "c =c.permute(0, 3, 1, 2)\n",
    "\n",
    "# c.size() = batch, col, row, out_channels\n",
    "print(c.size())\n",
    "print(out)\n",
    "print(c)\n",
    "# out.size = [batch_size, out_channels, row, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test 4d transform matrix\n",
    "def matrix3d_matrix1d(input_matrix, kernel_size ):\n",
    "    \n",
    "    input_row = input_matrix.size(0)\n",
    "    input_col = input_matrix.size(1)\n",
    "    \n",
    "    ks = kernel_size // 2\n",
    "    trans_subrow = len(input_matrix[0]) - ks -1\n",
    "    trans_row = trans_subrow * input_row\n",
    "    trans_col = kernel_size\n",
    "    transform_maxtrix = torch.zeros([trans_row , trans_col])\n",
    "    \n",
    "    for index in range(input_row):\n",
    "        \n",
    "        ls = input_matrix[index,:]\n",
    "        \n",
    "        for i in range(ks, len(ls) - ks):\n",
    "            transform_maxtrix[i-1 + index * trans_subrow,:] = ls[i-ks: i+ks+1]\n",
    "    return transform_maxtrix\n",
    "\n",
    "def myconv1d(input_m, kernel,kernel_size):\n",
    "    # batch_size, in_channels, in_row, in_col\n",
    "    \n",
    "    temp_m = input_m.reshape(-1,input_m.size(1))\n",
    "    res = matrix3d_matrix1d(temp_m, kernel_size )\n",
    "    \n",
    "    res = res.mm(kernel)\n",
    "    res = res.reshape(input_m.size(0),-1,input_m.size(2),kernel.size(1))\n",
    "    \n",
    "    return res \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 6, 1])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### test 4d transform matrix\n",
    "\n",
    "kernel_size = 3\n",
    "output_channels = 1\n",
    "input_matrix = torch.rand(2, 6, 6, 3)\n",
    "# batch_size, in_channels, in_row, in_col\n",
    "# batch_size, in_x, in_y, in_z\n",
    "\n",
    "kernel  = torch.rand([kernel_size,output_channels])\n",
    "\n",
    "d= myconv1d(input_matrix, kernel,kernel_size)\n",
    "d.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(img, conv_filter):\n",
    "   \n",
    "    if len(img.shape)!=3 or len(conv_filter.shape)!=4:\n",
    "        print(\"卷积运算所输入的维度不符合要求\")\n",
    "        sys.exit()\n",
    "        \n",
    "    if img.shape[-1] != conv_filter.shape[-1]:\n",
    "        print(\"卷积输入图片与卷积核的通道数不一致\")\n",
    "        sys.exit()\n",
    "        \n",
    "    img_h, img_w, img_ch = img.shape\n",
    "    filter_num, filter_h, filter_w, img_ch = conv_filter.shape\n",
    "    feature_h = img_h - filter_h + 1\n",
    "    feature_w = img_w - filter_w + 1\n",
    "\n",
    "    # 初始化输出的特征图片，由于没有使用零填充，图片尺寸会减小\n",
    "    img_out = np.zeros((feature_h, feature_w, filter_num))\n",
    "    img_matrix = np.zeros((feature_h*feature_w, filter_h*filter_w*img_ch))\n",
    "    filter_matrix = np.zeros((filter_h*filter_w*img_ch, filter_num))\n",
    "    \n",
    "    # 将输入图片张量转换成矩阵形式\n",
    "    for i in range(feature_h*feature_w):\n",
    "        for j in range(img_ch):\n",
    "            img_matrix[i, j*filter_h*filter_w:(j+1)*filter_h*filter_w] = \\\n",
    "            img[np.uint16(i/feature_w):np.uint16(i/feature_w+filter_h),np.uint16(i%feature_w):np.uint16(i%feature_w+filter_w),j].reshape(filter_h*filter_w)\n",
    "    \n",
    "    # 将卷积核张量转换成矩阵形式\n",
    "    for i in range(filter_num):\n",
    "        filter_matrix[:,i] = conv_filter[i,:].reshape(filter_w*filter_h*img_ch)\n",
    "    \n",
    "    feature_matrix = np.dot(img_matrix, filter_matrix)\n",
    "    \n",
    "    for i in range(filter_num):\n",
    "        img_out[:,:,i] = feature_matrix[:,i].reshape(feature_h, feature_w)\n",
    "    \n",
    "    return img_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3045, 0.3638, 0.1190, 0.0709, 0.3345, 0.7904],\n",
       "        [0.6410, 0.8664, 0.9376, 0.1281, 0.6148, 0.0498]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8109, 0.4977, 0.8461],\n",
       "        [0.4977, 0.8461, 0.6593],\n",
       "        [0.8461, 0.6593, 0.6308],\n",
       "        [0.6593, 0.6308, 0.4467],\n",
       "        [0.2395, 0.0494, 0.8369],\n",
       "        [0.0494, 0.8369, 0.6761],\n",
       "        [0.8369, 0.6761, 0.1070],\n",
       "        [0.6761, 0.1070, 0.8767]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_maxtrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_3conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "class flatten_conv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, in_row, in_col,\n",
    "                kernel_size, stride=1, padding=0, \n",
    "                dilation=1, groups=1, bias=True, padding_mode='zeros'):\n",
    "\n",
    "        super(flatten_conv2d, self).__init__()\n",
    "        \n",
    "        self.in_row = in_row\n",
    "        self.in_col = in_col\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.L1_weight = nn.Parameter(torch.Tensor(kernel_size, out_channels))\n",
    "        self.L1_bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "\n",
    "        \n",
    "        self.L1_weight.data.uniform_(-0.1, 0.1)\n",
    "        self.L1_bias.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "#         x = self.matrix3d_matrix1d(input, self.kernel_size )\n",
    "        # See the autograd section for explanation of what happens here.\n",
    "        res = test_fun.apply(input, self.L1_weight, self.L1_bias)\n",
    "#         res = input\n",
    "        return res\n",
    "    \n",
    "    def matrix3d_matrix1d(self, input_matrix, kernel_size ):\n",
    "\n",
    "        input_row = input_matrix.size(0)\n",
    "        input_col = input_matrix.size(1)\n",
    "        \n",
    "        ks = kernel_size // 2\n",
    "        trans_subrow = len(input_matrix[0]) - ks -1\n",
    "        trans_row = trans_subrow * input_row\n",
    "        trans_col = kernel_size\n",
    "        transform_maxtrix = torch.zeros([trans_row , trans_col])\n",
    "\n",
    "        for index in range(input_row):\n",
    "\n",
    "            ls = input_matrix[index,:]\n",
    "\n",
    "            for i in range(ks, len(ls) - ks):\n",
    "                transform_maxtrix[i-1 + index * trans_subrow,:] = ls[i-ks: i+ks+1]\n",
    "        return transform_maxtrix\n",
    "\n",
    "\n",
    "#     def extra_repr(self):\n",
    "#         # (Optional)Set the extra information about this module. You can test\n",
    "#         # it by printing an object of this class.\n",
    "#         return 'in_features={}, out_features={}, bias={}'.format(\n",
    "#             self.in_features, self.out_features, self.bias is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 6, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 6, 3])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "kernel_size = 3\n",
    "output_channels = 1\n",
    "input_matrix = torch.rand(1, 2, 6, 3)\n",
    "\n",
    "f = flatten_conv2d(in_channels=2, out_channels=1, in_row=3, in_col=3,\n",
    "                kernel_size=3)\n",
    "\n",
    "r = f(input_matrix)\n",
    "r.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_fun(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, bias):\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "        print(input.size())\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "#         print(grad_output)\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        \n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        \n",
    "        return grad_input, grad_weight, grad_bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "conv1 = nn.Conv1d(2,3,kernel_size)\n",
    "input_matrix = torch.rand(2, 2, 6)\n",
    "conv1(input_matrix).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3, 1])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7209, 0.7582, 0.7923],\n",
       "         [1.2069, 1.3946, 0.9410],\n",
       "         [1.5652, 1.2715, 0.5333],\n",
       "         [0.8409, 0.9237, 1.5476]],\n",
       "\n",
       "        [[1.4687, 1.5621, 1.1674],\n",
       "         [0.8757, 0.8300, 1.1598],\n",
       "         [0.8386, 1.1064, 0.9700],\n",
       "         [0.9292, 1.1963, 1.6553]]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = c.reshape(2,-1,3)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4304],\n",
       "        [0.2370]])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = matrix3d_matrix1d(c,kernel_size)\n",
    "myconv1d(d, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myconv1d(trans_m, kernel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
