{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Function\n",
    "def get_parameter_number(net):\n",
    "    total_num = sum(p.numel() for p in net.parameters())\n",
    "    trainable_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    return {'Total': total_num, 'Trainable': trainable_num}\n",
    "\n",
    "dtype = torch.float\n",
    "\n",
    "class RandomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, size, length):\n",
    "        self.len = length\n",
    "        self.data = torch.randn(length, *size ,dtype = dtype)\n",
    "        self.label = torch.rand(1, dtype = dtype)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "        \n",
    "def Random_DataLoader():\n",
    "    input_size = [3]\n",
    "\n",
    "    train_img_loader = DataLoader(dataset=RandomDataset(input_size, length = 100),\n",
    "                         batch_size=2, shuffle=True)\n",
    "    val_img_loader =  DataLoader(dataset=RandomDataset(input_size, length = 10),\n",
    "                         batch_size=2, shuffle=False)\n",
    "\n",
    "    return train_img_loader, val_img_loader\n",
    "\n",
    "\n",
    "trainloader, valloader =  Random_DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, input_features, output_features, bias=True):\n",
    "        super(Linear, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.output_features = output_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(output_features, input_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(output_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.weight.data.uniform_(-0.1, 0.1)\n",
    "        if bias is not None:\n",
    "            self.bias.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # See the autograd section for explanation of what happens here.\n",
    "        return LinearFunction.apply(input, self.weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        # (Optional)Set the extra information about this module. You can test\n",
    "        # it by printing an object of this class.\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "demo_net = Linear(3,1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(demo_net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = demo_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        break\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, bias=None):\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "        output = input.mm(weight.t())\n",
    "\n",
    "        \n",
    "        if bias is not None:\n",
    "            output += bias.unsqueeze(0).expand_as(output)\n",
    "            \n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \n",
    "        print(grad_output.size())\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        \n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        \n",
    "#         print(ctx.needs_input_grad)\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            print('weight:',weight.size())\n",
    "            grad_input = grad_output.mm(weight)\n",
    "\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = grad_output.t().mm(input)\n",
    "\n",
    "                 \n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            \n",
    "            grad_bias = grad_output.sum(0).squeeze(0)\n",
    "            grad_bias = grad_bias.view_as(bias)\n",
    "\n",
    "            \n",
    "            \n",
    "#         print('grad_output',grad_output)\n",
    "#         print('grad_input',grad_input)\n",
    "            \n",
    "        return grad_input, grad_weight, grad_bias\n",
    "        # there backward dl/dw, dl/db\n",
    "        # and the grad_output is dl/dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "weight: torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# test two demo backward\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "in_random = torch.rand([1,3])\n",
    "label = torch.Tensor([1])\n",
    "\n",
    "demo_net1 = Linear(3,2)\n",
    "demo_net2 = Linear(2,1)\n",
    "out_put = demo_net1(in_random)\n",
    "out_put = demo_net2(out_put)\n",
    "\n",
    "loss = criterion(out_put, label)\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test 2d transform matrix\n",
    "input_matrix = torch.rand(2, 6)\n",
    "\n",
    "kernel_size = 3\n",
    "input_channels = 2\n",
    "output_channels = 2\n",
    "ks = kernel_size // 2\n",
    "per_col = len(ls) - ks -1\n",
    "transform_maxtrix = torch.zeros([per_col * 2 , kernel_size])\n",
    "fil  = torch.rand([3,output_channels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(input_matrix)):\n",
    "    ls = input_matrix[index,:]\n",
    "    for i in range(ks, len(ls) - ks):\n",
    "        transform_maxtrix[i-1 + index * per_col,:] = ls[i-ks: i+ks+1]\n",
    "\n",
    "\n",
    "output_matrix = transform_maxtrix.mm(fil)\n",
    "output = output.T\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test reshape order\n",
    "a = np.array([[[111,112],[121,122]],[[211,212],[221,222]]])\n",
    "a.reshape(2,-1, order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test conv1d kernel and input shape\n",
    "# input size = [conv_num, kernel_size * in_channels]\n",
    "# kernel matirx shape = [kernel_size * in_channels, out_channels]\n",
    "\n",
    "# test no batch_size\n",
    "a = torch.rand([3,4,5])\n",
    "# a shape = [in_channels, row, col]\n",
    "a = a.reshape([3, -1])\n",
    "# a shape = [in_channels, row * col]\n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test 4d transform matrix\n",
    "\n",
    "a = torch.rand([2,3,4,5])\n",
    "b = a.reshape(-1,a.size(3))\n",
    "len_row = a.size(3)\n",
    "# b.size() = [batch_size * x * y, z]\n",
    "# print(a)\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test 4d transform matrix\n",
    "half_kernel_size = kernel_size // 2\n",
    "kernel_size = 3\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "res = torch.empty([0])\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "        res = torch.cat([res,temp],dim = 0)  \n",
    "    # there is copy, don't warry about editing other torch\n",
    "\n",
    "res = res.reshape(-1,kernel_size)\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test 4d transform matrix\n",
    "kernel = torch.rand([3,1])\n",
    "out = res.mm(kernel)\n",
    "print(out.size())\n",
    "c = out.reshape(2,3,4,-1)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test in_channels conv1\n",
    "a = torch.rand([2,3,4,5])\n",
    "# a.size() = batch_size, in_channels, row, col\n",
    "# a.size() = batch_size, row, col, in_channels\n",
    "a =a.permute(0, 2, 3, 1)\n",
    "a.size()\n",
    "len_row = a.size(3)\n",
    "b = a.reshape(-1,len_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test in_channels conv1\n",
    "\n",
    "kernel_size = 3\n",
    "half_kernel_size = kernel_size // 2\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "res = torch.empty([0])\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "        res = torch.cat([res,temp],dim = 0)  \n",
    "    # there is copy, don't warry about editing other torch\n",
    "\n",
    "res = res.reshape(-1,kernel_size)\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test in_channels conv1\n",
    "\n",
    "kernel = torch.rand([3,1])\n",
    "out = res.mm(kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test in_channels conv1\n",
    "\n",
    "c = out.reshape(2,4,5,-1)\n",
    "c =c.permute(0, 3, 1, 2)\n",
    "\n",
    "# c.size() = batch, col, row, out_channels\n",
    "print(c.size())\n",
    "# print(out)\n",
    "# print(c)\n",
    "# out.size = [batch_size, out_channels, row, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test row conv1\n",
    "\n",
    "c =c.permute(0, 1, 3, 2)\n",
    "# a.size() = batch_size, col, , out_channels\n",
    "\n",
    "print(c.size())\n",
    "len_row = c.size(3)\n",
    "b = c.reshape(-1,len_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test 4d transform matrix\n",
    "def matrix3d_matrix1d(input_matrix, kernel_size ):\n",
    "    \n",
    "    input_row = input_matrix.size(0)\n",
    "    input_col = input_matrix.size(1)\n",
    "    \n",
    "    ks = kernel_size // 2\n",
    "    trans_subrow = len(input_matrix[0]) - ks -1\n",
    "    trans_row = trans_subrow * input_row\n",
    "    trans_col = kernel_size\n",
    "    transform_maxtrix = torch.zeros([trans_row , trans_col])\n",
    "    \n",
    "    for index in range(input_row):\n",
    "        \n",
    "        ls = input_matrix[index,:]\n",
    "        \n",
    "        for i in range(ks, len(ls) - ks):\n",
    "            transform_maxtrix[i-1 + index * trans_subrow,:] = ls[i-ks: i+ks+1]\n",
    "    return transform_maxtrix\n",
    "\n",
    "def myconv1d(input_m, kernel,kernel_size):\n",
    "    # batch_size, in_channels, in_row, in_col\n",
    "    \n",
    "    temp_m = input_m.reshape(-1,input_m.size(1))\n",
    "    res = matrix3d_matrix1d(temp_m, kernel_size )\n",
    "    \n",
    "    res = res.mm(kernel)\n",
    "    res = res.reshape(input_m.size(0),-1,input_m.size(2),kernel.size(1))\n",
    "    \n",
    "    return res \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test row conv1\n",
    "\n",
    "\n",
    "kernel_size = 3\n",
    "half_kernel_size = kernel_size // 2\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "res = torch.empty([0])\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "        res = torch.cat([res,temp],dim = 0)  \n",
    "    # there is copy, don't warry about editing other torch\n",
    "\n",
    "res = res.reshape(-1,kernel_size)\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test row conv1\n",
    "\n",
    "kernel = torch.rand([3,1])\n",
    "out = res.mm(kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test in_channels conv1\n",
    "\n",
    "d = out.reshape(2, 1, 5,-1)\n",
    "d =d.permute(0, 1, 3, 2)\n",
    "\n",
    "# c.size() = batch, col, row, out_channels\n",
    "# print(c.size())\n",
    "# print(out)\n",
    "# print(c)\n",
    "# out.size = [batch_size, out_channels, row, col]\n",
    "d.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test col conv1\n",
    "\n",
    "e =d\n",
    "# a.size() = batch_size, col, , out_channels\n",
    "\n",
    "print(e.size())\n",
    "len_row = e.size(3)\n",
    "b = e.reshape(-1,len_row)\n",
    "\n",
    "kernel_size = 3\n",
    "half_kernel_size = kernel_size // 2\n",
    "index_start = half_kernel_size\n",
    "index_end = len_row - half_kernel_size\n",
    "\n",
    "res = torch.empty([0])\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_kernel_size : index+half_kernel_size+1]\n",
    "        res = torch.cat([res,temp],dim = 0)  \n",
    "    # there is copy, don't warry about editing other torch\n",
    "\n",
    "res = res.reshape(-1,kernel_size)\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test col conv1\n",
    "\n",
    "kernel = torch.rand([3,1])\n",
    "out = res.mm(kernel)\n",
    "\n",
    "f = out.reshape(2, 1, 2,-1)\n",
    "\n",
    "# c.size() = batch, col, row, out_channels\n",
    "# print(c.size())\n",
    "# print(out)\n",
    "# print(c)\n",
    "# out.size = [batch_size, out_channels, row, col]\n",
    "f.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test mul_out_channels, basis configure\n",
    "batch_size = 2\n",
    "in_channels = 3\n",
    "out_channels = 2\n",
    "row = 4\n",
    "col = 5\n",
    "my_input = torch.rand([batch_size,in_channels,row,col])\n",
    "L_wight_size = 3\n",
    "# a.size() = batch_size, row, col, in_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test mul_out_channels, in_channels part\n",
    "\n",
    "in_L =my_input.permute(0, 2, 3, 1)\n",
    "print('in_L:',my_input.size())\n",
    "\n",
    "len_row = in_L.size(3)\n",
    "b = in_L.reshape(-1,len_row)\n",
    "\n",
    "L_wight_size = 3\n",
    "half_L_ws = L_wight_size // 2\n",
    "index_start = half_L_ws\n",
    "index_end = len_row - half_L_ws\n",
    "\n",
    "res = []\n",
    "\n",
    "for i in b:\n",
    "    for index in range(index_start, index_end):\n",
    "        temp  = i[index-half_L_ws : index+half_L_ws+1]\n",
    "        res.append(temp)\n",
    "        \n",
    "res = torch.cat(res)  \n",
    "res = res.reshape(-1,L_wight_size)\n",
    "print('res:', res.size())\n",
    "\n",
    "\n",
    "\n",
    "L_weight = torch.rand([L_wight_size, out_channels])\n",
    "out_L = res.mm(L_weight)\n",
    "\n",
    "\n",
    "out_L = out_L.reshape(2,4,5,-1)\n",
    "out_L =out_L.permute(0, 3, 1, 2)\n",
    "\n",
    "print('out_L:',out_L.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test mul_out_channels, row part\n",
    "\n",
    "in_H =out_L.permute(1, 0, 3, 2)\n",
    "# in_H shape = out_channels, batch_size, col, row\n",
    "\n",
    "print('in_H:', out_L.size())\n",
    "print('permute in_H:', in_H.size())\n",
    "\n",
    "len_row = in_H.size(3)\n",
    "\n",
    "H_wight_size = 3\n",
    "half_H_ws = H_wight_size // 2\n",
    "index_start = half_H_ws\n",
    "index_end = len_row - half_H_ws\n",
    "\n",
    "\n",
    "res = []\n",
    "for per_channel in in_H:\n",
    "    per_channel = per_channel.reshape(-1,len_row)\n",
    "    # per_channel size = batch_size, col, row\n",
    "    # per_channel size = batch_size * col, row\n",
    "    temp_res = []\n",
    "    \n",
    "    for i in per_channel:\n",
    "        for index in range(index_start, index_end):\n",
    "            temp  = i[index-half_H_ws : index+half_H_ws+1]\n",
    "            temp_res.append(temp)\n",
    "            \n",
    "    temp_res = torch.cat(temp_res,dim = 0)\n",
    "    temp_res = temp_res.reshape(-1, H_wight_size)\n",
    "    res.append(temp_res)\n",
    "\n",
    "    \n",
    "res = torch.cat(res,dim = 0)\n",
    "res = res.reshape(out_channels, -1, H_wight_size)\n",
    "\n",
    "print('res:', res.size())\n",
    "\n",
    "out_H = []\n",
    "H_weight = torch.rand([out_channels, H_wight_size]) #out_channels,1])\n",
    "\n",
    "for i in range(out_channels):\n",
    "    sub_weight = H_weight[i,:]\n",
    "    sub_weight.unsqueeze_(1)\n",
    "    sub_feature = res[i,:,:]\n",
    "    temp = sub_feature.mm(sub_weight)\n",
    "    out_H.append(temp)\n",
    "\n",
    "out_H = torch.cat(out_H,dim=0)\n",
    "# print('out:', out.size())\n",
    "out_H = out_H.reshape(out_channels, batch_size, col,-1)\n",
    "out_H =out_H.permute(1, 0, 3, 2)\n",
    "print('out_H:', out_H.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test mul_out_channels, row part\n",
    "\n",
    "in_H =out_L.permute(1, 0, 3, 2)\n",
    "# in_H shape = out_channels, batch_size, col, row\n",
    "\n",
    "print('in_H:', out_L.size())\n",
    "print('permute in_H:', in_H.size())\n",
    "\n",
    "len_row = in_H.size(3)\n",
    "\n",
    "H_wight_size = 3\n",
    "half_H_ws = H_wight_size // 2\n",
    "index_start = half_H_ws\n",
    "index_end = len_row - half_H_ws\n",
    "\n",
    "\n",
    "res = []\n",
    "for per_channel in in_H:\n",
    "    per_channel = per_channel.reshape(-1,len_row)\n",
    "    # per_channel size = batch_size, col, row\n",
    "    # per_channel size = batch_size * col, row\n",
    "    temp_res = []\n",
    "    \n",
    "    for i in per_channel:\n",
    "        for index in range(index_start, index_end):\n",
    "            temp  = i[index-half_H_ws : index+half_H_ws+1]\n",
    "            temp_res.append(temp)\n",
    "            \n",
    "    temp_res = torch.cat(temp_res,dim = 0)\n",
    "    temp_res = temp_res.reshape(-1, H_wight_size)\n",
    "    res.append(temp_res)\n",
    "\n",
    "    \n",
    "res = torch.cat(res,dim = 0)\n",
    "res = res.reshape(out_channels, -1, H_wight_size)\n",
    "\n",
    "print('res:', res.size())\n",
    "\n",
    "out_H = []\n",
    "H_weight = torch.rand([out_channels, H_wight_size]) #out_channels,1])\n",
    "\n",
    "for i in range(out_channels):\n",
    "    sub_weight = H_weight[i,:]\n",
    "    sub_weight.unsqueeze_(1)\n",
    "    sub_feature = res[i,:,:]\n",
    "    temp = sub_feature.mm(sub_weight)\n",
    "    out_H.append(temp)\n",
    "\n",
    "out_H = torch.cat(out_H,dim=0)\n",
    "# print('out_H:', out_H.size())\n",
    "out_H = out_H.reshape(out_channels, batch_size, col,-1)\n",
    "out_H =out_H.permute(1, 0, 3, 2)\n",
    "print('out_H:', out_H.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test mul_out_channels, col part\n",
    "new_row = out_H.size(2)\n",
    "in_V =out_H.permute(1, 0, 2, 3)\n",
    "# in_V shape = out_channels, batch_size, row, col \n",
    "\n",
    "print('in_V:', out_H.size())\n",
    "print('permute in_V:', in_V.size())\n",
    "\n",
    "len_row = in_V.size(3)\n",
    "\n",
    "V_wight_size = 3\n",
    "half_V_ws = V_wight_size // 2\n",
    "index_start = half_V_ws\n",
    "index_end = len_row - half_V_ws\n",
    "\n",
    "\n",
    "res = []\n",
    "for per_channel in in_V:\n",
    "    per_channel = per_channel.reshape(-1,len_row)\n",
    "    # per_channel size = batch_size, row, col\n",
    "    # per_channel size = batch_size * row, col\n",
    "    temp_res = []\n",
    "    \n",
    "    for i in per_channel:\n",
    "        for index in range(index_start, index_end):\n",
    "            temp  = i[index-half_V_ws : index+half_V_ws+1]\n",
    "            temp_res.append(temp)\n",
    "            \n",
    "    temp_res = torch.cat(temp_res,dim = 0)\n",
    "    temp_res = temp_res.reshape(-1, V_wight_size)\n",
    "    res.append(temp_res)\n",
    "\n",
    "    \n",
    "res = torch.cat(res,dim = 0)\n",
    "res = res.reshape(out_channels, -1, V_wight_size)\n",
    "\n",
    "print('res:', res.size())\n",
    "\n",
    "out_V = []\n",
    "V_weight = torch.rand([out_channels, V_wight_size]) #out_channels,1])\n",
    "\n",
    "for i in range(out_channels):\n",
    "    sub_weight = V_weight[i,:]\n",
    "    sub_weight.unsqueeze_(1)\n",
    "    sub_feature = res[i,:,:]\n",
    "    temp = sub_feature.mm(sub_weight)\n",
    "    out_V.append(temp)\n",
    "\n",
    "out_V = torch.cat(out_V,dim=0)\n",
    "# print('out_V:', out_V.size())\n",
    "out_V = out_V.reshape(out_channels, batch_size, new_row,-1)\n",
    "out_V =out_V.permute(1, 0, 2, 3)\n",
    "print('out_V:', out_V.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test mul_out_channels class\n",
    "\n",
    "class test_mul_out_channels():\n",
    "    def __init__(self, out_channels):\n",
    "        self.row = 0\n",
    "        self.col = 0\n",
    "        self.out_channels = out_channels\n",
    "#         self.in_channels = in_channels\n",
    "        self.batch_size =0\n",
    "        \n",
    "    def full_conv(self,input):\n",
    "        self.batch_size = input.size(0)\n",
    "        self.in_channels = input.size(1)\n",
    "        self.row = input.size(2)\n",
    "        self.col = input.size(3)\n",
    "        \n",
    "        in_L =input.permute(0, 2, 3, 1)\n",
    "        out_L = self.conv1d_L(in_L, wight_size = self.in_channels)\n",
    "        out_L =out_L.permute(0, 3, 1, 2)\n",
    "        print('out_L:', out_L.size())\n",
    "        \n",
    "        \n",
    "        \n",
    "        in_H =out_L.permute(1, 0, 3, 2)\n",
    "        out_H = self.conv1d_VH(in_H, wight_size =3 )\n",
    "        out_H =out_H.permute(1, 0, 3, 2)\n",
    "        print('out_H:', out_H.size())\n",
    "\n",
    "        in_V =out_H.permute(1, 0, 2, 3)\n",
    "        out_V = self.conv1d_VH(in_V, wight_size =3 )\n",
    "        out_V =out_V.permute(1, 0, 2, 3)\n",
    "        print('out_V:', out_V.size())\n",
    "        return out_V\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    def conv1d_L(self, in_matrix, wight_size):\n",
    "        \n",
    "\n",
    "#         print('in_L:',my_input.size())\n",
    "\n",
    "        len_row = in_matrix.size(3)\n",
    "        b = in_matrix.reshape(-1,len_row)\n",
    "\n",
    "        L_wight_size = wight_size\n",
    "        half_L_ws = L_wight_size // 2\n",
    "        index_start = half_L_ws\n",
    "        index_end = len_row - half_L_ws\n",
    "\n",
    "        res = []\n",
    "\n",
    "        for i in b:\n",
    "            for index in range(index_start, index_end):\n",
    "                temp  = i[index-half_L_ws : index+half_L_ws+1]\n",
    "                res.append(temp)\n",
    "\n",
    "        res = torch.cat(res)  \n",
    "        res = res.reshape(-1,L_wight_size)\n",
    "\n",
    "        print(res.size())\n",
    "\n",
    "        L_weight = torch.rand([L_wight_size, self.out_channels])\n",
    "        out_L = res.mm(L_weight)\n",
    "        out_L = out_L.reshape(self.batch_size , self.row , self.col, -1)\n",
    "\n",
    "        return out_L\n",
    "        \n",
    "        \n",
    "        \n",
    "    def conv1d_VH(self, in_matrix, wight_size):\n",
    "\n",
    "        out_shape = list(in_matrix.size())\n",
    "        out_shape = out_shape[:-1] + [-1]\n",
    "        in_V =in_matrix\n",
    "\n",
    "        len_row = in_V.size(3)\n",
    "        \n",
    "        V_wight_size = wight_size\n",
    "        half_V_ws = V_wight_size // 2\n",
    "        index_start = half_V_ws\n",
    "        index_end = len_row - half_V_ws\n",
    "\n",
    "\n",
    "        res = []\n",
    "        for per_channel in in_V:\n",
    "            per_channel = per_channel.reshape(-1,len_row)\n",
    "            # per_channel size = batch_size, row, col\n",
    "            # per_channel size = batch_size * row, col\n",
    "            temp_res = []\n",
    "\n",
    "            for i in per_channel:\n",
    "                for index in range(index_start, index_end):\n",
    "                    temp  = i[index-half_V_ws : index+half_V_ws+1]\n",
    "                    temp_res.append(temp)\n",
    "\n",
    "            temp_res = torch.cat(temp_res,dim = 0)\n",
    "            temp_res = temp_res.reshape(-1, V_wight_size)\n",
    "            res.append(temp_res)\n",
    "\n",
    "\n",
    "        res = torch.cat(res,dim = 0)\n",
    "        res = res.reshape(self.out_channels, -1, V_wight_size)\n",
    "\n",
    "#         print('res:', res.size())\n",
    "\n",
    "        out_V = []\n",
    "        V_weight = torch.rand([self.out_channels, V_wight_size]) #out_channels,1])\n",
    "\n",
    "        for i in range(out_channels):\n",
    "            sub_weight = V_weight[i,:]\n",
    "            sub_weight.unsqueeze_(1)\n",
    "            sub_feature = res[i,:,:]\n",
    "            temp = sub_feature.mm(sub_weight)\n",
    "            out_V.append(temp)\n",
    "\n",
    "        out_V = torch.cat(out_V,dim=0)\n",
    "        # print('out_V:', out_V.size())\n",
    "        out_V = out_V.reshape(*out_shape)\n",
    "        return out_V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 5])\n",
      "torch.Size([40, 3])\n",
      "out_L: torch.Size([2, 2, 4, 5])\n",
      "out_H: torch.Size([2, 2, 2, 5])\n",
      "out_V: torch.Size([2, 2, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2, 3])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#test mul_out_channels class\n",
    "\n",
    "batch_size = 2\n",
    "in_channels = 3\n",
    "out_channels = 2\n",
    "row = 4\n",
    "col = 5\n",
    "my_input = torch.rand([batch_size,in_channels,row,col])\n",
    "print(my_input.size())\n",
    "\n",
    "\n",
    "S = test_mul_out_channels(out_channels =2)\n",
    "c = S.full_conv(my_input )\n",
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test Module class\n",
    "class flatten_conv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, in_row, in_col,\n",
    "                kernel_size, stride=1, padding=0, \n",
    "                dilation=1, groups=1, bias=True, padding_mode='zeros'):\n",
    "\n",
    "        super(flatten_conv2d, self).__init__()\n",
    "        \n",
    "#         self.in_row = in_row\n",
    "#         self.in_col = in_col\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "#         self.kernel_size = kernel_size\n",
    "        wight_size = self.in_channels\n",
    "        self.L1_weight = nn.Parameter(torch.Tensor(in_channels, out_channels))\n",
    "        self.L1_bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        \n",
    "        self.V1_weight = nn.Parameter(torch.Tensor(kernel_size, out_channels))\n",
    "        self.V1_bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        \n",
    "        self.H1_weight = nn.Parameter(torch.Tensor(kernel_size, out_channels))\n",
    "        self.H1_bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "\n",
    "        \n",
    "        self.L1_weight.data.uniform_(-0.1, 0.1)\n",
    "        self.L1_bias.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "        self.V1_weight.data.uniform_(-0.1, 0.1)\n",
    "        self.V1_bias.data.uniform_(-0.1, 0.1)\n",
    "               \n",
    "        self.H1_weight.data.uniform_(-0.1, 0.1)\n",
    "        self.H1_bias.data.uniform_(-0.1, 0.1)\n",
    "         \n",
    "    def forward(self, input):\n",
    "#         x = self.matrix3d_matrix1d(input, self.kernel_size )\n",
    "        # See the autograd section for explanation of what happens here.\n",
    "#         res = test_fun.apply(input, self.L1_weight, self.L1_bias)\n",
    "        \n",
    "        out_L = conv1d_L.apply(input, self.L1_weight, self.L1_bias)\n",
    "        print('out_L:', out_L.size())\n",
    "        \n",
    "        out_V = conv1d_V.apply(out_L, self.V1_weight, self.V1_bias)\n",
    "        print('out_V:', out_V.size())\n",
    "        \n",
    "        out_H = conv1d_H.apply(out_V, self.H1_weight, self.H1_bias)\n",
    "        print('out_H:', out_H.size())\n",
    "        \n",
    "        return out_H\n",
    "\n",
    "#     def extra_repr(self):\n",
    "#         # (Optional)Set the extra information about this module. You can test\n",
    "#         # it by printing an object of this class.\n",
    "#         return 'in_features={}, out_features={}, bias={}'.format(\n",
    "#             self.in_features, self.out_features, self.bias is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_L: torch.Size([2, 3, 4, 5])\n",
      "out_V: torch.Size([2, 3, 2, 5])\n",
      "out_H: torch.Size([2, 3, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 3])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#test mul_out_channels class\n",
    "\n",
    "batch_size = 2\n",
    "in_channels = 3\n",
    "out_channels = 3\n",
    "row = 4\n",
    "col = 5\n",
    "kernel_size = 3\n",
    "my_input = torch.rand([batch_size,in_channels,row,col])\n",
    "\n",
    "S = flatten_conv2d(in_channels= in_channels, \n",
    "                   out_channels= out_channels , \n",
    "                   in_row=row, in_col=col, kernel_size=kernel_size)\n",
    "\n",
    "my_output = S(my_input )\n",
    "my_output.size()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv1d_L(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, bias):\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "        \n",
    "        in_L =input.permute(0, 2, 3, 1)\n",
    "        \n",
    "        out_shape = list(in_L.size())\n",
    "        out_shape = out_shape[:-1] + [-1]\n",
    "        \n",
    "        \n",
    "        len_row = in_L.size(3)\n",
    "        L_wight_size = weight.size(0)\n",
    "        half_L_ws = L_wight_size // 2\n",
    "        index_start = half_L_ws\n",
    "        index_end = len_row - half_L_ws\n",
    "        \n",
    "        b = in_L.reshape(-1,len_row)\n",
    "        res = []\n",
    "\n",
    "        for i in b:\n",
    "            for index in range(index_start, index_end):\n",
    "                temp  = i[index-half_L_ws : index+half_L_ws+1]\n",
    "                res.append(temp)\n",
    "\n",
    "        res = torch.cat(res)  \n",
    "        res = res.reshape(-1,L_wight_size)\n",
    "\n",
    "    \n",
    "        out_L = res.mm(weight)\n",
    "        out_L = out_L + bias\n",
    "        out_L = out_L.reshape(*out_shape)\n",
    "        out_L = out_L.permute(0, 3, 1, 2)\n",
    "\n",
    "        return out_L\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        print('conv1d_L:',ctx.needs_input_grad)\n",
    "\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        \n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        \n",
    "        return grad_input, grad_weight, grad_bias\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv1d_V(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, bias):\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "        in_V =input.permute(1, 0, 3, 2)\n",
    "        \n",
    "        \n",
    "        out_channels = in_V.size(0)\n",
    "        \n",
    "        out_shape = list(in_V.size())\n",
    "        out_shape = out_shape[:-1] + [-1]\n",
    "        \n",
    "        \n",
    "        len_row = in_V.size(3)\n",
    "        wight_size = weight.size(0)\n",
    "        half_ws = wight_size // 2\n",
    "        index_start = half_ws\n",
    "        index_end = len_row - half_ws\n",
    "        \n",
    "\n",
    "\n",
    "        res = []\n",
    "        for per_channel in in_V:\n",
    "            per_channel = per_channel.reshape(-1,len_row)\n",
    "            \n",
    "            temp_res = []\n",
    "\n",
    "            for i in per_channel:\n",
    "                for index in range(index_start, index_end):\n",
    "                    temp  = i[index-half_ws : index+half_ws+1]\n",
    "                    temp_res.append(temp)\n",
    "\n",
    "            temp_res = torch.cat(temp_res,dim = 0)\n",
    "            temp_res = temp_res.reshape(-1, wight_size)\n",
    "            res.append(temp_res)\n",
    "\n",
    "\n",
    "        res = torch.cat(res,dim = 0)\n",
    "        res = res.reshape(out_channels, -1, wight_size)\n",
    "\n",
    "        out_V = []\n",
    "\n",
    "        for i in range(out_channels):\n",
    "            sub_weight = weight[:,i]\n",
    "            sub_weight.unsqueeze_(1)\n",
    "            sub_feature = res[i,:,:]\n",
    "            sub_bias = bias[i]\n",
    "            \n",
    "            temp = sub_feature.mm(sub_weight)\n",
    "            temp +=  sub_bias\n",
    "\n",
    "            \n",
    "            out_V.append(temp)\n",
    "\n",
    "        out_V = torch.cat(out_V,dim=0)\n",
    "        # print('out_V:', out_V.size())\n",
    "        out_V = out_V.reshape(*out_shape)\n",
    "        \n",
    "        out_V =out_V.permute(1, 0, 3, 2)\n",
    "        \n",
    "        return out_V\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        print('conv1d_V:',ctx.needs_input_grad)\n",
    "        \n",
    "#         print(grad_output)\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        \n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        \n",
    "        return grad_input, grad_weight, grad_bias\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv1d_H(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, bias):\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "        \n",
    "        in_matrix =input.permute(1, 0, 2, 3)\n",
    "        \n",
    "        \n",
    "        out_channels = in_matrix.size(0)\n",
    "        \n",
    "        out_shape = list(in_matrix.size())\n",
    "        out_shape = out_shape[:-1] + [-1]\n",
    "        \n",
    "        \n",
    "        len_row = in_matrix.size(3)\n",
    "        wight_size = weight.size(0)\n",
    "        half_ws = wight_size // 2\n",
    "        index_start = half_ws\n",
    "        index_end = len_row - half_ws\n",
    "        \n",
    "\n",
    "\n",
    "        res = []\n",
    "        for per_channel in in_matrix:\n",
    "            per_channel = per_channel.reshape(-1,len_row)\n",
    "            \n",
    "            temp_res = []\n",
    "\n",
    "            for i in per_channel:\n",
    "                for index in range(index_start, index_end):\n",
    "                    temp  = i[index-half_ws : index+half_ws+1]\n",
    "                    temp_res.append(temp)\n",
    "\n",
    "            temp_res = torch.cat(temp_res,dim = 0)\n",
    "            temp_res = temp_res.reshape(-1, wight_size)\n",
    "            res.append(temp_res)\n",
    "\n",
    "\n",
    "        res = torch.cat(res,dim = 0)\n",
    "        res = res.reshape(out_channels, -1, wight_size)\n",
    "\n",
    "        out_matrix = []\n",
    "        \n",
    "\n",
    "        for i in range(out_channels):\n",
    "            sub_weight = weight[:,i]\n",
    "            sub_weight.unsqueeze_(1)\n",
    "            sub_feature = res[i,:,:]\n",
    "            sub_bias = bias[i]\n",
    "            print('sub_feature,',sub_feature.size())\n",
    "            \n",
    "            temp = sub_feature.mm(sub_weight)\n",
    "            temp +=  sub_bias\n",
    "\n",
    "            \n",
    "            out_matrix.append(temp)\n",
    "\n",
    "        out_matrix = torch.cat(out_matrix,dim=0)\n",
    "        # print('out_V:', out_V.size())\n",
    "        out_matrix = out_matrix.reshape(*out_shape)\n",
    "        \n",
    "        out_matrix =out_matrix.permute(1, 0, 2, 3)\n",
    "        \n",
    "        return out_matrix\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        print('conv1d_H:',ctx.needs_input_grad)\n",
    "        print('H.grad_output:,',grad_output.size())\n",
    "        \n",
    "        \n",
    "#         print(grad_output)\n",
    "#         print(grad_output)\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        \n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        \n",
    "        \n",
    "        \n",
    "        ############\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            \n",
    "#             grad_weight = grad_output.t().mm(input)\n",
    "\n",
    "#             print(grad_output)\n",
    "            print(grad_output.size())\n",
    "            print(weight.size())\n",
    "#             grad_input = grad_output.mm(weight)\n",
    "\n",
    "\n",
    "        ##########\n",
    "        \n",
    "        return grad_input, grad_weight, grad_bias\n",
    "\n",
    "    def transform_matrix(input):\n",
    "                \n",
    "        in_matrix =input.permute(1, 0, 2, 3)    \n",
    "        out_channels = in_matrix.size(0)\n",
    "        \n",
    "        out_shape = list(in_matrix.size())\n",
    "        out_shape = out_shape[:-1] + [-1]\n",
    "        \n",
    "        \n",
    "        len_row = in_matrix.size(3)\n",
    "        wight_size = weight.size(0)\n",
    "        half_ws = wight_size // 2\n",
    "        index_start = half_ws\n",
    "        index_end = len_row - half_ws\n",
    "        \n",
    "\n",
    "\n",
    "        res = []\n",
    "        for per_channel in in_matrix:\n",
    "            per_channel = per_channel.reshape(-1,len_row)\n",
    "            \n",
    "            temp_res = []\n",
    "\n",
    "            for i in per_channel:\n",
    "                for index in range(index_start, index_end):\n",
    "                    temp  = i[index-half_ws : index+half_ws+1]\n",
    "                    temp_res.append(temp)\n",
    "\n",
    "            temp_res = torch.cat(temp_res,dim = 0)\n",
    "            temp_res = temp_res.reshape(-1, wight_size)\n",
    "            res.append(temp_res)\n",
    "\n",
    "\n",
    "        res = torch.cat(res,dim = 0)\n",
    "        res = res.reshape(out_channels, -1, wight_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_L: torch.Size([1, 1, 4, 5])\n",
      "out_V: torch.Size([1, 1, 2, 5])\n",
      "sub_feature, torch.Size([6, 3])\n",
      "out_H: torch.Size([1, 1, 2, 3])\n",
      "conv1d_H: (True, True, True)\n",
      "H.grad_output:, torch.Size([1, 1, 2, 3])\n",
      "torch.Size([1, 1, 2, 3])\n",
      "torch.Size([3, 1])\n",
      "conv1d_V: (True, True, True)\n",
      "conv1d_L: (False, True, True)\n"
     ]
    }
   ],
   "source": [
    "#test mul_out_channels backward\n",
    "# ctx.needs_input_grad\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "batch_size = 1\n",
    "in_channels = 1\n",
    "out_channels = 1\n",
    "row = 4\n",
    "col = 5\n",
    "kernel_size = 3\n",
    "my_input = torch.rand([batch_size,in_channels,row,col])\n",
    "\n",
    "S = flatten_conv2d(in_channels= in_channels, \n",
    "                   out_channels= out_channels , \n",
    "                   in_row=row, in_col=col, kernel_size=kernel_size)\n",
    "\n",
    "my_output = S(my_input )\n",
    "label = torch.ones_like(my_output)\n",
    "\n",
    "\n",
    "loss = criterion(my_output, label)\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "conv1 = nn.Conv1d(2,3,kernel_size)\n",
    "input_matrix = torch.rand(2, 2, 6)\n",
    "conv1(input_matrix).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        print(ctx.needs_input_grad)\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = grad_output.mm(weight)\n",
    "\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = grad_output.t().mm(input)\n",
    "\n",
    "                 \n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            \n",
    "            grad_bias = grad_output.sum(0).squeeze(0)\n",
    "            grad_bias = grad_bias.view_as(bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c.reshape(2,-1,3)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = matrix3d_matrix1d(c,kernel_size)\n",
    "myconv1d(d, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myconv1d(trans_m, kernel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
